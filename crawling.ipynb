{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ELISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv\n",
    "\n",
    "##### CHẶN THÔNG BÁO #####\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "prefs = {\n",
    "    \"credentials_enable_service\": False, \n",
    "    \"profile.password_manager_enabled\": False, \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "\n",
    "web_url = \"https://elise.vn/ao-den-co-phoi-luoi-dinh-day-hoa-fs2412024tswobk.html\"\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.maximize_window()\n",
    "driver.get(web_url)\n",
    "\n",
    "\n",
    "##### MÃ SẢN PHẨM #####\n",
    "sku_element = driver.find_element(By.CSS_SELECTOR, \"div.product.attribute.sku\")\n",
    "sku_value = sku_element.text\n",
    "print(sku_value)\n",
    "time.sleep(2)\n",
    "\n",
    "##### TÊN SẢN PHẨM #####\n",
    "name_element = driver.find_element(By.CSS_SELECTOR, \"div.product-name-label h1\")\n",
    "name_value = name_element.text\n",
    "print(name_value)\n",
    "time.sleep(2)\n",
    "\n",
    "##### MÔ TẢ #####\n",
    "try:\n",
    "    description_element = driver.find_element(By.CSS_SELECTOR, \"div.value.std\")\n",
    "    description_value = description_element.text.replace(\"\\n\", \" _ \")\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    description_value = None\n",
    "\n",
    "print(description_value)\n",
    "\n",
    "\n",
    "\n",
    "##### PHẦN TRĂM GIẢM GIÁ #####\n",
    "try:\n",
    "    sale_label = driver.find_element(By.CSS_SELECTOR, \"span.product-label.sale-label span\")\n",
    "    sale_value = sale_label.text\n",
    "except:\n",
    "    sale_value = None\n",
    "print(sale_value)\n",
    "\n",
    "##### GIÁ #####\n",
    "product_info_price = driver.find_element(By.CSS_SELECTOR,\"div.product-info-price\")\n",
    "try:\n",
    "    special_price = product_info_price.find_element(By.CSS_SELECTOR,\"span.special-price\")\n",
    "    old_price = product_info_price.find_element(By.CSS_SELECTOR,\"span.old-price\")\n",
    "\n",
    "    special_price_value = special_price.text\n",
    "    old_price_value = old_price.text\n",
    "except:\n",
    "    old_price_value = product_info_price.text\n",
    "    special_price_value  = None\n",
    "print(old_price_value)\n",
    "print(special_price_value)\n",
    "\n",
    "##### KÍCH THƯỚC #####\n",
    "wrapper_element = driver.find_element(By.CSS_SELECTOR, \"div.product-options-wrapper\")\n",
    "size_elements = wrapper_element.find_elements(By.CSS_SELECTOR, \"div.swatch-option.text\")\n",
    "\n",
    "size_texts = [size_element.text for size_element in size_elements]\n",
    "sizes_value = \"_\".join(size_texts)\n",
    "print(size_texts)\n",
    "time.sleep(2)\n",
    "\n",
    "##### HÌNH ẢNH #####\n",
    "image_urls = []\n",
    "image_elements = driver.find_elements(By.CSS_SELECTOR, \"div.product.item-image.imgzoom img\")\n",
    "\n",
    "for image_element in image_elements:\n",
    "    image_url = image_element.get_attribute('src')\n",
    "    image_urls.append(image_url)\n",
    "print(image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lapto\\AppData\\Local\\Temp\\ipykernel_7164\\192031132.py\", line 7, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lapto\\AppData\\Local\\Temp\\ipykernel_7164\\192031132.py\", line 7, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Users\\lapto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu quá trình cào dữ liệu...\n",
      "=== PHASE 1: Crawling category ===\n",
      "Initialized directory structure for elise\n",
      "Không có thông báo popup\n",
      "Opening: http://store.elise.vn/thoi-trang-nu (Category: thoi-trang-nu)\n",
      "Processing: thoi-trang-nu - Page 1\n",
      "Created collection directory: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\n",
      "Saved HTML: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\html.txt\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_TRẮNG_NHĂN_CỔ_BẺ_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_TRẮNG_NHĂN_CỔ_BẺ_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_ĐEN_VÂN_NỔI_BUỘC_NƠ_CỔ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_ĐEN_VÂN_NỔI_BUỘC_NƠ_CỔ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TAFTA_LỤA_ĐEN_CẮT_CÚP_EO_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TAFTA_LỤA_ĐEN_CẮT_CÚP_EO_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_REN_HOA_HT_KEM_CỔ_ĐỨC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_REN_HOA_HT_KEM_CỔ_ĐỨC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ÔM_KẺ_NỀN_BE_PHỐI_CỔ_TRẮNG_BẤU_MÍ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ÔM_KẺ_NỀN_BE_PHỐI_CỔ_TRẮNG_BẤU_MÍ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CỔ_XẾP_BẤU_MÍ_CHÉO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CỔ_XẾP_BẤU_MÍ_CHÉO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_SỢI_ĐỎ_RƯỢU_VANG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_SỢI_ĐỎ_RƯỢU_VANG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_CAM_GẠCH_TÚI_DỌC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_CAM_GẠCH_TÚI_DỌC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_SỢI_HỒNG_CAM_CƠI_TÚI_TRƯỚC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_SỢI_HỒNG_CAM_CƠI_TÚI_TRƯỚC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_REN_HOA_ĐEN_TỈA_CHÂN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_REN_HOA_ĐEN_TỈA_CHÂN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_NGẮN_TAY_SỢI_HỒNG_CAM_NƠ_TÚI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_NGẮN_TAY_SỢI_HỒNG_CAM_NƠ_TÚI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_ĐUÔI_TÔM_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_ĐUÔI_TÔM_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_2_DÂY_+_KHOÁC_LỬNG_TÍM_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_2_DÂY_+_KHOÁC_LỬNG_TÍM_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_ĐỎ_RƯỢI_VANG_VẠT_CONG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_ĐỎ_RƯỢI_VANG_VẠT_CONG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_CAM_GẠCH_VẠT_CHÉO_CÚC_GẤU_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_CAM_GẠCH_VẠT_CHÉO_CÚC_GẤU_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_2_DÂY_REN_HOA_ĐEN_BÈO_NGỰC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_2_DÂY_REN_HOA_ĐEN_BÈO_NGỰC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THUN_ĐEN_XẾP_NHÚN_HOA_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THUN_ĐEN_XẾP_NHÚN_HOA_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_KAKI_ĐEN_PHỐI_THUN_TĂM_BUỘC_DÂY_VAI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_KAKI_ĐEN_PHỐI_THUN_TĂM_BUỘC_DÂY_VAI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_ĐEN_XẾP_NHÚN_HOA_THÂN_SAU_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_ĐEN_XẾP_NHÚN_HOA_THÂN_SAU_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CHÂN_DẬP_LY_ĐAI_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CHÂN_DẬP_LY_ĐAI_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_LỬNG_TRẮNG_TÚI_DỌC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_LỬNG_TRẮNG_TÚI_DỌC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SOOC_UMI_ĐEN_XẾP_LY_ĐÍNH_LOGO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SOOC_UMI_ĐEN_XẾP_LY_ĐÍNH_LOGO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_DÀI_ĐEN_VÂN_BOOM_GẤU_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_DÀI_ĐEN_VÂN_BOOM_GẤU_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_UMI_BE_NÂU_XẾP_LY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_UMI_BE_NÂU_XẾP_LY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_ĐEN_BOOM_GẤU_ĐAI_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_ĐEN_BOOM_GẤU_ĐAI_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_DẬP_NHĂN_NÂU_TÚI_SƯỜN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_DẬP_NHĂN_NÂU_TÚI_SƯỜN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_UMI_TRẮNG_XẺ_TRƯỚC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_UMI_TRẮNG_XẺ_TRƯỚC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_THUN_ĐEN_PHỐI_VẢI_LINEN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_THUN_ĐEN_PHỐI_VẢI_LINEN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_DẬP_NHĂN_NÂU_ỐP_TÚI_NGỰC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_DẬP_NHĂN_NÂU_ỐP_TÚI_NGỰC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_TRẮNG_MAY_HOA_NỔI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_TRẮNG_MAY_HOA_NỔI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_PHỐI_HOA_TƠ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_PHỐI_HOA_TƠ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_NÂU_SN_NGỰC_ĐÍNH_LOGO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_NÂU_SN_NGỰC_ĐÍNH_LOGO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_THÊU_HOA_NỔI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_THÊU_HOA_NỔI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_ĐEN_PHỐI_VẢI_LINEN_ĐÍNH_LOGO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_ĐEN_PHỐI_VẢI_LINEN_ĐÍNH_LOGO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_VÂN_TRẮNG_CỔ_TÀU_CHUN_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_VÂN_TRẮNG_CỔ_TÀU_CHUN_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_LƯỚI_CHUN_TRẮNG_VẠT_PHỦ_LỆCH_VAI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_LƯỚI_CHUN_TRẮNG_VẠT_PHỦ_LỆCH_VAI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XANH_RÊU_ĐẬM_TAY_CHỒNG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XANH_RÊU_ĐẬM_TAY_CHỒNG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SỢI_HỒNG_CAM_CỔ_BUỘC_DÂY_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SỢI_HỒNG_CAM_CỔ_BUỘC_DÂY_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_LỤA_ĐEN_CỔ_V_LẬT_XẾP_NHÚN_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_LỤA_ĐEN_CỔ_V_LẬT_XẾP_NHÚN_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_CAM_NUDE_PEPLUM_CHẠY_BÈO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_CAM_NUDE_PEPLUM_CHẠY_BÈO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_XANH_LÁ_ĐẬM_TÀ_BÊN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_XANH_LÁ_ĐẬM_TÀ_BÊN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_TAFTA_LỤA_ĐEN_CẠP_LIỀN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_TAFTA_LỤA_ĐEN_CẠP_LIỀN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_KAKI_NÂU_XẺ_GIỮA_DIỄU_CHỈ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_KAKI_NÂU_XẺ_GIỮA_DIỄU_CHỈ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_ĐEN_PHỦ_TÀ_CẠP_CHÉO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_ĐEN_PHỦ_TÀ_CẠP_CHÉO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_BE_VÀNG_TÚI_CHÉO_CẠP_DÂY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_BE_VÀNG_TÚI_CHÉO_CẠP_DÂY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_SẠN_TRẮNG_DÂY_CẠP_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_SẠN_TRẮNG_DÂY_CẠP_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_TAFTA_LỤA_ĐEN_CỔ_LỆCH_ĐAI_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_TAFTA_LỤA_ĐEN_CỔ_LỆCH_ĐAI_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_KÈM_CARAVAT_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_KÈM_CARAVAT_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_BE_CỔ_ĐỨC_XẾP_LY_TAY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_BE_CỔ_ĐỨC_XẾP_LY_TAY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_XANH_LÁ_ĐẬM_XẾP_LY_CHÉO_DÂY_VẠT_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_XANH_LÁ_ĐẬM_XẾP_LY_CHÉO_DÂY_VẠT_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_TƠ_KEM_CỔ_V_HOA_NGỰC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_TƠ_KEM_CỔ_V_HOA_NGỰC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_IN_HOA_LY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_IN_HOA_LY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SẠN_TRẮNG_CỔ_VEST_CHUN_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SẠN_TRẮNG_CỔ_VEST_CHUN_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_SUÔNG_TƠ_HOA_HỒNG_ĐỎ_BÈO_BÊN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_SUÔNG_TƠ_HOA_HỒNG_ĐỎ_BÈO_BÊN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_LƯỚI_HOA_HỒNG_ĐỎ_XẾP_TẦNG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_LƯỚI_HOA_HỒNG_ĐỎ_XẾP_TẦNG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_NHĂN_HỒNG_BÈO_GẤU_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_NHĂN_HỒNG_BÈO_GẤU_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XÒE_SỢI_HỒNG_ĐỖ_CỔ_ĐỨC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XÒE_SỢI_HỒNG_ĐỖ_CỔ_ĐỨC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_VOAN_HOA_HỒNG_CỔ_V_CHÉO_VIỀN_REN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_VOAN_HOA_HỒNG_CỔ_V_CHÉO_VIỀN_REN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_HOA_HỒNG_CỔ_THUYỀN_BÈO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_HOA_HỒNG_CỔ_THUYỀN_BÈO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SUÔNG_ĐỎ_SẪM_CỔ_V_ĐÍNH_NƠ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SUÔNG_ĐỎ_SẪM_CỔ_V_ĐÍNH_NƠ_2.jpg\n",
      "Saved JSON: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\data.json\n",
      "Updated CSV files:\n",
      "- Added 60 new links to list_add.csv\n",
      "- Added 60 links to list_attempt.csv\n",
      "Processing: thoi-trang-nu - Page 1\n",
      "Created collection directory: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\n",
      "Saved HTML: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\html.txt\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_TRẮNG_NHĂN_CỔ_BẺ_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_TRẮNG_NHĂN_CỔ_BẺ_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_ĐEN_VÂN_NỔI_BUỘC_NƠ_CỔ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_ĐEN_VÂN_NỔI_BUỘC_NƠ_CỔ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TAFTA_LỤA_ĐEN_CẮT_CÚP_EO_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TAFTA_LỤA_ĐEN_CẮT_CÚP_EO_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_REN_HOA_HT_KEM_CỔ_ĐỨC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_REN_HOA_HT_KEM_CỔ_ĐỨC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ÔM_KẺ_NỀN_BE_PHỐI_CỔ_TRẮNG_BẤU_MÍ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ÔM_KẺ_NỀN_BE_PHỐI_CỔ_TRẮNG_BẤU_MÍ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CỔ_XẾP_BẤU_MÍ_CHÉO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CỔ_XẾP_BẤU_MÍ_CHÉO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_SỢI_ĐỎ_RƯỢU_VANG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_SỢI_ĐỎ_RƯỢU_VANG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_CAM_GẠCH_TÚI_DỌC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_CAM_GẠCH_TÚI_DỌC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_SỢI_HỒNG_CAM_CƠI_TÚI_TRƯỚC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_SỢI_HỒNG_CAM_CƠI_TÚI_TRƯỚC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_REN_HOA_ĐEN_TỈA_CHÂN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_REN_HOA_ĐEN_TỈA_CHÂN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_NGẮN_TAY_SỢI_HỒNG_CAM_NƠ_TÚI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_NGẮN_TAY_SỢI_HỒNG_CAM_NƠ_TÚI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_ĐUÔI_TÔM_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_ĐUÔI_TÔM_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_2_DÂY_+_KHOÁC_LỬNG_TÍM_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_2_DÂY_+_KHOÁC_LỬNG_TÍM_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_ĐỎ_RƯỢI_VANG_VẠT_CONG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_ĐỎ_RƯỢI_VANG_VẠT_CONG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_CAM_GẠCH_VẠT_CHÉO_CÚC_GẤU_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_CAM_GẠCH_VẠT_CHÉO_CÚC_GẤU_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_2_DÂY_REN_HOA_ĐEN_BÈO_NGỰC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_2_DÂY_REN_HOA_ĐEN_BÈO_NGỰC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THUN_ĐEN_XẾP_NHÚN_HOA_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THUN_ĐEN_XẾP_NHÚN_HOA_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_KAKI_ĐEN_PHỐI_THUN_TĂM_BUỘC_DÂY_VAI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_KAKI_ĐEN_PHỐI_THUN_TĂM_BUỘC_DÂY_VAI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_ĐEN_XẾP_NHÚN_HOA_THÂN_SAU_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_THÔ_ĐEN_XẾP_NHÚN_HOA_THÂN_SAU_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CHÂN_DẬP_LY_ĐAI_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CHÂN_DẬP_LY_ĐAI_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_LỬNG_TRẮNG_TÚI_DỌC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_LỬNG_TRẮNG_TÚI_DỌC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SOOC_UMI_ĐEN_XẾP_LY_ĐÍNH_LOGO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SOOC_UMI_ĐEN_XẾP_LY_ĐÍNH_LOGO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_DÀI_ĐEN_VÂN_BOOM_GẤU_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_DÀI_ĐEN_VÂN_BOOM_GẤU_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_UMI_BE_NÂU_XẾP_LY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_UMI_BE_NÂU_XẾP_LY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_ĐEN_BOOM_GẤU_ĐAI_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_ĐEN_BOOM_GẤU_ĐAI_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_DẬP_NHĂN_NÂU_TÚI_SƯỜN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_THÔ_DẬP_NHĂN_NÂU_TÚI_SƯỜN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_UMI_TRẮNG_XẺ_TRƯỚC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_UMI_TRẮNG_XẺ_TRƯỚC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_THUN_ĐEN_PHỐI_VẢI_LINEN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CHÂN_VÁY_THUN_ĐEN_PHỐI_VẢI_LINEN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_DẬP_NHĂN_NÂU_ỐP_TÚI_NGỰC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_DẬP_NHĂN_NÂU_ỐP_TÚI_NGỰC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_TRẮNG_MAY_HOA_NỔI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_TRẮNG_MAY_HOA_NỔI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_PHỐI_HOA_TƠ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_PHỐI_HOA_TƠ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_NÂU_SN_NGỰC_ĐÍNH_LOGO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_UMI_BE_NÂU_SN_NGỰC_ĐÍNH_LOGO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_THÊU_HOA_NỔI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_THÊU_HOA_NỔI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_ĐEN_PHỐI_VẢI_LINEN_ĐÍNH_LOGO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_ĐEN_PHỐI_VẢI_LINEN_ĐÍNH_LOGO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_VÂN_TRẮNG_CỔ_TÀU_CHUN_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_VÂN_TRẮNG_CỔ_TÀU_CHUN_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_LƯỚI_CHUN_TRẮNG_VẠT_PHỦ_LỆCH_VAI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_LƯỚI_CHUN_TRẮNG_VẠT_PHỦ_LỆCH_VAI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XANH_RÊU_ĐẬM_TAY_CHỒNG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XANH_RÊU_ĐẬM_TAY_CHỒNG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SỢI_HỒNG_CAM_CỔ_BUỘC_DÂY_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SỢI_HỒNG_CAM_CỔ_BUỘC_DÂY_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_LỤA_ĐEN_CỔ_V_LẬT_XẾP_NHÚN_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_LỤA_ĐEN_CỔ_V_LẬT_XẾP_NHÚN_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_CAM_NUDE_PEPLUM_CHẠY_BÈO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_CAM_NUDE_PEPLUM_CHẠY_BÈO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_XANH_LÁ_ĐẬM_TÀ_BÊN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_XANH_LÁ_ĐẬM_TÀ_BÊN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_TAFTA_LỤA_ĐEN_CẠP_LIỀN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_TAFTA_LỤA_ĐEN_CẠP_LIỀN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_KAKI_NÂU_XẺ_GIỮA_DIỄU_CHỈ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_KAKI_NÂU_XẺ_GIỮA_DIỄU_CHỈ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_ĐEN_PHỦ_TÀ_CẠP_CHÉO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_ĐEN_PHỦ_TÀ_CẠP_CHÉO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_BE_VÀNG_TÚI_CHÉO_CẠP_DÂY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_BE_VÀNG_TÚI_CHÉO_CẠP_DÂY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_SẠN_TRẮNG_DÂY_CẠP_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\CV_SẠN_TRẮNG_DÂY_CẠP_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_TAFTA_LỤA_ĐEN_CỔ_LỆCH_ĐAI_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_TAFTA_LỤA_ĐEN_CỔ_LỆCH_ĐAI_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_KÈM_CARAVAT_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_KÈM_CARAVAT_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_BE_CỔ_ĐỨC_XẾP_LY_TAY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_THÔ_BE_CỔ_ĐỨC_XẾP_LY_TAY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_XANH_LÁ_ĐẬM_XẾP_LY_CHÉO_DÂY_VẠT_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_XANH_LÁ_ĐẬM_XẾP_LY_CHÉO_DÂY_VẠT_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_TƠ_KEM_CỔ_V_HOA_NGỰC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_TƠ_KEM_CỔ_V_HOA_NGỰC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_IN_HOA_LY_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_THUN_TRẮNG_IN_HOA_LY_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SẠN_TRẮNG_CỔ_VEST_CHUN_EO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SẠN_TRẮNG_CỔ_VEST_CHUN_EO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_SUÔNG_TƠ_HOA_HỒNG_ĐỎ_BÈO_BÊN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_SUÔNG_TƠ_HOA_HỒNG_ĐỎ_BÈO_BÊN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_LƯỚI_HOA_HỒNG_ĐỎ_XẾP_TẦNG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_LƯỚI_HOA_HỒNG_ĐỎ_XẾP_TẦNG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_NHĂN_HỒNG_BÈO_GẤU_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_NHĂN_HỒNG_BÈO_GẤU_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XÒE_SỢI_HỒNG_ĐỖ_CỔ_ĐỨC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XÒE_SỢI_HỒNG_ĐỖ_CỔ_ĐỨC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_VOAN_HOA_HỒNG_CỔ_V_CHÉO_VIỀN_REN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_VOAN_HOA_HỒNG_CỔ_V_CHÉO_VIỀN_REN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_HOA_HỒNG_CỔ_THUYỀN_BÈO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_HOA_HỒNG_CỔ_THUYỀN_BÈO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SUÔNG_ĐỎ_SẪM_CỔ_V_ĐÍNH_NƠ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_SUÔNG_ĐỎ_SẪM_CỔ_V_ĐÍNH_NƠ_2.jpg\n",
      "Saved JSON: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\data.json\n",
      "Updated CSV files:\n",
      "- Added 0 new links to list_add.csv\n",
      "- Added 60 links to list_attempt.csv\n",
      "Processing: thoi-trang-nu - Page 1\n",
      "Created collection directory: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\n",
      "Saved HTML: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\html.txt\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_TRẮNG_NHĂN_CỔ_BẺ_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_XỐP_TRẮNG_NHĂN_CỔ_BẺ_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_ĐEN_VÂN_NỔI_BUỘC_NƠ_CỔ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TƠ_ĐEN_VÂN_NỔI_BUỘC_NƠ_CỔ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TAFTA_LỤA_ĐEN_CẮT_CÚP_EO_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_TAFTA_LỤA_ĐEN_CẮT_CÚP_EO_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_REN_HOA_HT_KEM_CỔ_ĐỨC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_REN_HOA_HT_KEM_CỔ_ĐỨC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ÔM_KẺ_NỀN_BE_PHỐI_CỔ_TRẮNG_BẤU_MÍ_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ÔM_KẺ_NỀN_BE_PHỐI_CỔ_TRẮNG_BẤU_MÍ_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CỔ_XẾP_BẤU_MÍ_CHÉO_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ĐẦM_ĐEN_CỔ_XẾP_BẤU_MÍ_CHÉO_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_SỢI_ĐỎ_RƯỢU_VANG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_SỢI_ĐỎ_RƯỢU_VANG_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_CAM_GẠCH_TÚI_DỌC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\QUẦN_SUÔNG_CAM_GẠCH_TÚI_DỌC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_SỢI_HỒNG_CAM_CƠI_TÚI_TRƯỚC_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_SỢI_HỒNG_CAM_CƠI_TÚI_TRƯỚC_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_REN_HOA_ĐEN_TỈA_CHÂN_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\JUPE_REN_HOA_ĐEN_TỈA_CHÂN_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_NGẮN_TAY_SỢI_HỒNG_CAM_NƠ_TÚI_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\VEST_NGẮN_TAY_SỢI_HỒNG_CAM_NƠ_TÚI_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_ĐUÔI_TÔM_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SM_TƠ_ĐEN_CỔ_ĐỨC_ĐUÔI_TÔM_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_2_DÂY_+_KHOÁC_LỬNG_TÍM_ĐÍNH_HOA_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\SET_ĐẦM_2_DÂY_+_KHOÁC_LỬNG_TÍM_ĐÍNH_HOA_2.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_ĐỎ_RƯỢI_VANG_VẠT_CONG_1.jpg\n",
      "Saved Image: E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data\\elise\\2025\\05\\20\\09_49\\list_view\\thoi-trang-nu_1\\images\\ÁO_SỢI_ĐỎ_RƯỢI_VANG_VẠT_CONG_2.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv\n",
    "\n",
    "##### PATH + LINK #####\n",
    "\n",
    "base_save_dir = r'E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data'\n",
    "web_url = \"https://elise.vn/\"\n",
    "\n",
    "##### FUNCTION TẠO THƯ MỤC #####\n",
    "\n",
    "def extract_website_name(url):\n",
    "    \"\"\"\n",
    "    Lấy tên website từ URL, ví dụ: 'https://elise.vn/' -> 'elise'\n",
    "    \"\"\"\n",
    "    match = re.search(r\"https?://(?:www\\.)?([^./]+)\", url)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "start_time = datetime.now()\n",
    "year = start_time.strftime(\"%Y\")\n",
    "month = start_time.strftime(\"%m\")\n",
    "day = start_time.strftime(\"%d\")\n",
    "hour_minute = start_time.strftime(\"%H_%M\")\n",
    "\n",
    "def initialize_directory_structure(base_save_dir, web_url):\n",
    "    \"\"\"\n",
    "    Tạo cấu trúc thư mục cơ bản theo yêu cầu:\n",
    "    website > năm > tháng > ngày > giờ_phút > list_view | detail_view | CSVs\n",
    "    \"\"\"\n",
    "    website_name = extract_website_name(web_url)\n",
    "    \n",
    "    website_dir = os.path.join(base_save_dir, website_name)\n",
    "    os.makedirs(website_dir, exist_ok=True)\n",
    "    \n",
    "    list_info_all_path = os.path.join(website_dir, \"list_info_all.csv\")\n",
    "    if not os.path.exists(list_info_all_path):\n",
    "        with open(list_info_all_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"url\"])  \n",
    "    \n",
    "    year_dir = os.path.join(website_dir, year)\n",
    "    month_dir = os.path.join(year_dir, month)\n",
    "    day_dir = os.path.join(month_dir, day)\n",
    "    time_dir = os.path.join(day_dir, hour_minute)\n",
    "    \n",
    "    os.makedirs(year_dir, exist_ok=True)\n",
    "    os.makedirs(month_dir, exist_ok=True)\n",
    "    os.makedirs(day_dir, exist_ok=True)\n",
    "    os.makedirs(time_dir, exist_ok=True)\n",
    "    \n",
    "    list_view_dir = os.path.join(time_dir, \"list_view\")\n",
    "    detail_view_dir = os.path.join(time_dir, \"detail_view\")\n",
    "    \n",
    "    os.makedirs(list_view_dir, exist_ok=True)\n",
    "    os.makedirs(detail_view_dir, exist_ok=True)\n",
    "    \n",
    "    list_attempt_path = os.path.join(time_dir, \"list_attempt.csv\")\n",
    "    list_add_path = os.path.join(time_dir, \"list_add.csv\")\n",
    "    list_done_path = os.path.join(time_dir, \"list_done.csv\")\n",
    "    detail_attempt_path = os.path.join(time_dir, \"detail_attempt.csv\")\n",
    "    \n",
    "    for path in [list_attempt_path, list_add_path, list_done_path]:\n",
    "        if not os.path.exists(path):\n",
    "            with open(path, 'w', encoding='utf-8', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"url\"]) \n",
    "    \n",
    "    if not os.path.exists(detail_attempt_path):\n",
    "        with open(detail_attempt_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"sku\", \"name\", \"sale\", \"old_price\", \"special_price\", \"sizes\", \"description\", \"url\", \"images\"])\n",
    "    \n",
    "    print(f\"Initialized directory structure for {website_name}\")\n",
    "    \n",
    "    return {\n",
    "        'website_dir': website_dir,\n",
    "        'time_dir': time_dir,\n",
    "        'list_view_dir': list_view_dir,\n",
    "        'detail_view_dir': detail_view_dir,\n",
    "        'list_attempt_path': list_attempt_path,\n",
    "        'list_add_path': list_add_path,\n",
    "        'list_done_path': list_done_path,\n",
    "        'detail_attempt_path': detail_attempt_path,\n",
    "        'list_info_all_path': list_info_all_path\n",
    "    }\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\"Hàm để đọc dữ liệu từ file CSV và trả về một set.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader, None)  \n",
    "        return {row[0] for row in reader if row and row[0] != \"url\"}\n",
    "\n",
    "def append_csv(file_path, data):\n",
    "    \"\"\"Hàm để lưu dữ liệu vào file CSV theo kiểu append.\"\"\"\n",
    "    file_exists = os.path.isfile(file_path) and os.path.getsize(file_path) > 0\n",
    "    \n",
    "    with open(file_path, \"a\", encoding=\"utf-8\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"url\"])\n",
    "        for item in data:\n",
    "            writer.writerow([item])\n",
    "\n",
    "def update_product_links(paths, product_links):\n",
    "    \"\"\"\n",
    "    Cập nhật các file CSV theo quy trình:\n",
    "    - So sánh list_attempt với list_info_all để tìm ra các links mới (list_add)\n",
    "    - Thêm các links mới vào list_info_all và list_add\n",
    "    - Thêm tất cả các links vào list_attempt\n",
    "    \"\"\"\n",
    "    list_info_all = load_csv(paths['list_info_all_path'])\n",
    "    list_attempt = set(product_links) \n",
    "    \n",
    "    list_add = list_attempt - list_info_all\n",
    "    \n",
    "    if list_add:\n",
    "        append_csv(paths['list_info_all_path'], list_add)\n",
    "        append_csv(paths['list_add_path'], list_add)\n",
    "    \n",
    "    append_csv(paths['list_attempt_path'], list_attempt)\n",
    "    \n",
    "    print(f\"Updated CSV files:\")\n",
    "    print(f\"- Added {len(list_add)} new links to list_add.csv\")\n",
    "    print(f\"- Added {len(list_attempt)} links to list_attempt.csv\")\n",
    "    \n",
    "    return list_add\n",
    "\n",
    "def create_collection_directory(list_view_dir, collection_name, pagination_text):\n",
    "    \"\"\"\n",
    "    Tạo thư mục collection_{pagination} trong list_view\n",
    "    \"\"\"\n",
    "    collection_dir = os.path.join(list_view_dir, f\"{collection_name}_{pagination_text}\")\n",
    "    images_dir = os.path.join(collection_dir, \"images\")\n",
    "    \n",
    "    os.makedirs(collection_dir, exist_ok=True)\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Created collection directory: {collection_dir}\")\n",
    "    \n",
    "    return collection_dir, images_dir\n",
    "\n",
    "def save_collection_product_data(folder_path, products, actions):\n",
    "    \"\"\"Lưu dữ liệu sản phẩm từ collection view và trả về danh sách các links.\"\"\"\n",
    "    image_folder = os.path.join(folder_path, \"images\")\n",
    "    \n",
    "    product_links = []\n",
    "    \n",
    "    for product in products:\n",
    "        try:\n",
    "            product_element = product.find_element(By.CSS_SELECTOR, \"div.product-top a\")\n",
    "            product_href = product_element.get_attribute('href')\n",
    "            product_links.append(product_href)\n",
    "            \n",
    "            try:\n",
    "                image_name = product.find_element(By.CSS_SELECTOR, \"div.product.details.product-item-details h5.product.name.product-item-name\").text\n",
    "                image_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", image_name.replace(\" \", \"_\")) + \".jpg\"\n",
    "            except:\n",
    "                image_name = f\"product_{len(product_links)}.jpg\"\n",
    "            \n",
    "            image_element = product.find_element(By.CSS_SELECTOR, \"div.product-top img\")\n",
    "            image_url = image_element.get_attribute(\"src\")\n",
    "            \n",
    "            if image_url:\n",
    "                response = requests.get(image_url)\n",
    "                if response.status_code == 200:\n",
    "                    image_path = os.path.join(image_folder, image_name)\n",
    "                    with open(image_path, \"wb\") as file:\n",
    "                        file.write(response.content)\n",
    "                    print(f\"Saved Image: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing collection product: {e}\")\n",
    "    \n",
    "    json_path = os.path.join(folder_path, \"data.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(product_links, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saved Collection JSON: {json_path}\")\n",
    "    \n",
    "    return product_links\n",
    "\n",
    "def crawl_collections():\n",
    "    \"\"\"\n",
    "    Hàm thực hiện việc cào tất cả các links sản phẩm từ các bộ sưu tập\n",
    "    \"\"\"\n",
    "    paths = initialize_directory_structure(base_save_dir, web_url)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    lookbook_url = f\"{web_url.rstrip('/')}/lookbook\"\n",
    "    driver.get(lookbook_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    visited_collections = set()\n",
    "    collection_page = 1 \n",
    "    \n",
    "    while True:    \n",
    "        collections = driver.find_elements(By.CSS_SELECTOR, \"li.item-lookbook\")\n",
    "        print(f\"Found {len(collections)} collections on page {collection_page}\")\n",
    "        \n",
    "        for idx, collection in enumerate(collections):\n",
    "            if idx >= 2:\n",
    "                break\n",
    "            try:\n",
    "                url_element = collection.find_element(By.CSS_SELECTOR, \"div.item-image a\")\n",
    "                url_value = url_element.get_attribute('href')\n",
    "                \n",
    "                if url_value in visited_collections:\n",
    "                    continue\n",
    "                \n",
    "                visited_collections.add(url_value)\n",
    "                \n",
    "                name_element = collection.find_element(By.CSS_SELECTOR, \"div.item-content-info div.content h1\")\n",
    "                name_value = name_element.text\n",
    "                clean_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", name_value.replace(\" \", \"_\"))\n",
    "                \n",
    "                print(f\"Processing collection ({idx+1}/{len(collections)}): {name_value} - {url_value}\")\n",
    "                \n",
    "                driver.execute_script(f\"window.open('{url_value}');\")\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "                time.sleep(2)\n",
    "                \n",
    "                collection_dir, _ = create_collection_directory(paths['list_view_dir'], clean_name, \"1\")\n",
    "                \n",
    "                save_html_source(collection_dir, driver)\n",
    "                \n",
    "                products = driver.find_elements(By.CSS_SELECTOR, \"div.item div.item-content-wrapper\")\n",
    "                print(f\"Found {len(products)} products in collection: {name_value}\")\n",
    "                \n",
    "                product_links = save_collection_product_data(collection_dir, products, actions)\n",
    "                \n",
    "                update_product_links(paths, product_links)\n",
    "                \n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing collection: {e}\")\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "        try:\n",
    "            see_more = driver.find_element(By.CSS_SELECTOR, \"div.lookbook-actions span.button\")\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", see_more)\n",
    "            time.sleep(1)\n",
    "            see_more.click()\n",
    "            print(\"Clicked 'Xem thêm' button\")\n",
    "            time.sleep(3)  \n",
    "            collection_page += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Không tìm thấy nút 'Xem thêm' hoặc đã hết collections: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Hoàn thành quá trình cào collections, đã cào {len(visited_collections)} bộ sưu tập\")\n",
    "    driver.quit()\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def create_detail_directory(detail_view_dir, sku, product_name):\n",
    "    \"\"\"\n",
    "    Tạo thư mục trong detail_view theo cấu trúc:\n",
    "    part_X > {năm_tháng_ngày_giờ_phút}_{sku}_{name}\n",
    "    \"\"\"\n",
    "    part_folders = [f for f in os.listdir(detail_view_dir) if f.startswith(\"part_\")]\n",
    "    \n",
    "    if not part_folders:\n",
    "        part_folder = os.path.join(detail_view_dir, \"part_1\")\n",
    "        os.makedirs(part_folder, exist_ok=True)\n",
    "    else:\n",
    "        part_folder = os.path.join(detail_view_dir, sorted(part_folders)[-1])\n",
    "        if len(os.listdir(part_folder)) >= 300:\n",
    "            part_num = len(part_folders) + 1\n",
    "            part_folder = os.path.join(detail_view_dir, f\"part_{part_num}\")\n",
    "            os.makedirs(part_folder, exist_ok=True)\n",
    "    \n",
    "    clean_product_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", product_name.replace(\" \", \"_\"))\n",
    "    \n",
    "    timestamp = f\"{year}_{month}_{day}_{hour_minute}\"\n",
    "    item_folder = os.path.join(part_folder, f\"{timestamp}_{sku}_{clean_product_name}\")\n",
    "    os.makedirs(item_folder, exist_ok=True)\n",
    "    \n",
    "    image_folder = os.path.join(item_folder, \"images\")\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    \n",
    "    return item_folder, image_folder\n",
    "\n",
    "def save_html_source(folder_path, driver, filename=\"html.txt\"):\n",
    "    \"\"\"Lưu source HTML của trang hiện tại vào file.\"\"\"\n",
    "    html_content = driver.page_source\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "    print(f\"Saved HTML: {file_path}\")\n",
    "\n",
    "def save_product_data(folder_path, products, actions):\n",
    "    \"\"\"Lưu dữ liệu sản phẩm từ list view và trả về danh sách các links.\"\"\"\n",
    "    image_folder = os.path.join(folder_path, \"images\")\n",
    "    \n",
    "    product_links = []\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        try:\n",
    "            actions.move_to_element(product).perform()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            product_element = product.find_element(By.CSS_SELECTOR, \"div.product-top.has > a, div.product-top > a\")\n",
    "            product_href = product_element.get_attribute('href')\n",
    "            product_links.append(product_href)\n",
    "            \n",
    "            product_images = product.find_elements(By.CSS_SELECTOR, \"div.product-top.has > a.product.photo.product-item-photo > div.item-xmedia > div.product-image-wrapper > div.image-thumbnail > img, div.product-top > a.product.photo.product-item-photo > div.item-xmedia > div.product-image-wrapper > div.image-thumbnail.product-image-hover > img\")\n",
    "            image_counters = {}\n",
    "            \n",
    "            for img in product_images:\n",
    "                img_url = img.get_attribute(\"src\")\n",
    "                if \"data:image\" in img_url:  \n",
    "                    img_url = img.get_attribute(\"data-src\")\n",
    "                    \n",
    "                if not img_url or \"data:image\" in img_url:\n",
    "                    continue\n",
    "                \n",
    "                alt_text = img.get_attribute(\"alt\") or f\"product_{len(product_links)}\"\n",
    "                clean_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", alt_text.replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "                \n",
    "                if clean_name not in image_counters:\n",
    "                    image_counters[clean_name] = 1\n",
    "                else:\n",
    "                    image_counters[clean_name] += 1\n",
    "                \n",
    "                image_name = f\"{clean_name}_{image_counters[clean_name]}.jpg\"\n",
    "                image_path = os.path.join(image_folder, image_name)\n",
    "                \n",
    "                try:\n",
    "                    response = requests.get(img_url)\n",
    "                    if response.status_code == 200:\n",
    "                        with open(image_path, \"wb\") as file:\n",
    "                            file.write(response.content)\n",
    "                        print(f\"Saved Image: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving image {img_url}: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "    \n",
    "    json_path = os.path.join(folder_path, \"data.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(product_links, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saved JSON: {json_path}\")\n",
    "    \n",
    "    return product_links\n",
    "\n",
    "def scrape_product_detail(driver, product_url, paths):\n",
    "    \"\"\"\n",
    "    Lấy chi tiết sản phẩm từ trang detail và lưu vào thư mục tương ứng.\n",
    "    Cập nhật list_done.csv và detail_attempt.csv\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(product_url)\n",
    "        time.sleep(10)\n",
    "        \n",
    "        sku_value = driver.find_element(By.CSS_SELECTOR, \"div.product.attribute.sku\").text.strip()\n",
    "        name_value = driver.find_element(By.CSS_SELECTOR, \"div.product-name-label h1\").text.strip()\n",
    "        \n",
    "        if \":\" in sku_value:\n",
    "            sku_value = sku_value.split(\":\")[1].strip()\n",
    "        \n",
    "        try:\n",
    "            sale_value = driver.find_element(By.CSS_SELECTOR, \"span.product-label.sale-label span\").text\n",
    "        except:\n",
    "            sale_value = None\n",
    "        \n",
    "        product_info_price = driver.find_element(By.CSS_SELECTOR, \"div.product-info-price\")\n",
    "        try:\n",
    "            special_price_value = product_info_price.find_element(By.CSS_SELECTOR,\"span.special-price\").text\n",
    "            old_price_value = product_info_price.find_element(By.CSS_SELECTOR,\"span.old-price\").text\n",
    "        except:\n",
    "            old_price_value = product_info_price.text\n",
    "            special_price_value = None\n",
    "        \n",
    "        size_elements = driver.find_elements(By.CSS_SELECTOR, \"div.swatch-option.text\")\n",
    "        sizes_value = \"_\".join([size.text for size in size_elements])\n",
    "        \n",
    "        ##### MÔ TẢ #####\n",
    "        try:\n",
    "            description_element = driver.find_element(By.CSS_SELECTOR, \"div.value.std\")\n",
    "            description_value = description_element.text.replace(\"\\n\", \" _ \")\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            description_value = None\n",
    "        \n",
    "        print(f\"Mô tả: {description_value}\")\n",
    "        \n",
    "        image_urls = []\n",
    "        image_elements = driver.find_elements(By.CSS_SELECTOR, \"div.product.item-image.imgzoom img\")\n",
    "        for image_element in image_elements:\n",
    "            image_url = image_element.get_attribute('src')\n",
    "            if image_url:\n",
    "                image_urls.append(image_url)\n",
    "        \n",
    "        item_folder, image_folder = create_detail_directory(\n",
    "            paths['detail_view_dir'], \n",
    "            sku_value, \n",
    "            name_value\n",
    "        )\n",
    "        \n",
    "        save_html_source(item_folder, driver)\n",
    "        \n",
    "        product_data = {\n",
    "            \"sku\": sku_value,\n",
    "            \"name\": name_value,\n",
    "            \"sale\": sale_value,\n",
    "            \"old_price\": old_price_value,\n",
    "            \"special_price\": special_price_value,\n",
    "            \"sizes\": sizes_value,\n",
    "            \"description\": description_value,\n",
    "            \"url\": product_url,\n",
    "            \"images\": image_urls\n",
    "        }\n",
    "        \n",
    "        json_path = os.path.join(item_folder, \"data.json\")\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(product_data, json_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        for idx, image_url in enumerate(image_urls, start=1):\n",
    "            image_name = f\"{sku_value}_{idx:02}.jpg\"\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(image_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(image_path, \"wb\") as file:\n",
    "                        file.write(response.content)\n",
    "                    print(f\"Saved Image: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving image {image_url}: {e}\")\n",
    "        \n",
    "        append_csv(paths['list_done_path'], [product_url])\n",
    "        \n",
    "        detail_attempt_exists = os.path.isfile(paths['detail_attempt_path']) and os.path.getsize(paths['detail_attempt_path']) > 0\n",
    "        \n",
    "        with open(paths['detail_attempt_path'], \"a\", encoding=\"utf-8\", newline='') as f:\n",
    "            fieldnames = [\"sku\", \"name\", \"sale\", \"old_price\", \"special_price\", \"sizes\", \"description\", \"url\", \"images\"]\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            \n",
    "            if not detail_attempt_exists:\n",
    "                writer.writeheader()\n",
    "            \n",
    "            data_to_write = product_data.copy()\n",
    "            data_to_write[\"images\"] = json.dumps(product_data[\"images\"], ensure_ascii=False)\n",
    "            \n",
    "            writer.writerow(data_to_write)\n",
    "        \n",
    "        print(f\"Successfully scraped product: {name_value} ({sku_value})\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {product_url}: {e}\")\n",
    "        return False\n",
    "\n",
    "##### CHẶN THÔNG BÁO #####\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "prefs = {\n",
    "    \"credentials_enable_service\": False, \n",
    "    \"profile.password_manager_enabled\": False, \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "##### MAIN FUNCTION #####\n",
    "\n",
    "def crawl_links():\n",
    "    \"\"\"\n",
    "    Hàm thực hiện việc cào tất cả các links sản phẩm trước\n",
    "    \"\"\"\n",
    "    paths = initialize_directory_structure(base_save_dir, web_url)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver.get(web_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try: \n",
    "        close_button = driver.find_element(By.CSS_SELECTOR, \"div[id='close-button-1454703513200']\")\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(close_button).click().perform()\n",
    "    except:\n",
    "        print(\"Không có thông báo popup\")\n",
    "    \n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    menu_button = driver.find_element(By.CSS_SELECTOR, \"div.action-menu-responsive\")\n",
    "    actions.move_to_element(menu_button).perform()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    categorys = driver.find_elements(By.CSS_SELECTOR, \"li.static-menu.level0 > a, li.category-menu.level0 > a, li.level1 > a\")\n",
    "    keywords = [\"nu\", \"dam\", \"vay\", \"ao\", \"quan\", \"phu-kien\", \"giay\", \"tui\", \"trang-suc\", \"outlet\"]\n",
    "    # keywords = [\"dam\", \"vay\"]\n",
    "    pattern = r\"/([^/]+?)(?:\\.html)?$\"\n",
    "    \n",
    "    for category in categorys:\n",
    "        category_href = category.get_attribute('href')\n",
    "        \n",
    "        if any(keyword in category_href for keyword in keywords):\n",
    "            match = re.search(pattern, category_href)\n",
    "            category_name = match.group(1) if match else \"unknown\"\n",
    "            \n",
    "            print(f\"Opening: {category_href} (Category: {category_name})\")\n",
    "            \n",
    "            driver.execute_script(f\"window.open('{category_href}');\")\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            time.sleep(2)\n",
    "            \n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    pagination = driver.find_element(By.CSS_SELECTOR, \n",
    "                        \"div.bottom-pagination > div.toolbar.toolbar-products > div.pages.list-inline > ul.pagination > li.item.current > a, \" +\n",
    "                        \"div.pager > div.pages.list-inline > ul.pagination > li.item.current > a\")\n",
    "                    pagination_text = pagination.text\n",
    "                except:\n",
    "                    pagination_text = \"1\"\n",
    "                \n",
    "                print(f\"Processing: {category_name} - Page {pagination_text}\")\n",
    "                \n",
    "                category_dir, _ = create_collection_directory(paths['list_view_dir'], category_name, pagination_text)\n",
    "                \n",
    "                save_html_source(category_dir, driver)\n",
    "                \n",
    "                main = driver.find_element(By.CSS_SELECTOR, \"ol.products.list.items.product-items.row\")\n",
    "                products = main.find_elements(By.CSS_SELECTOR, \n",
    "                    \"li.item.product.product-item-info.product-item.col-xs-12.col-md-6, \" +\n",
    "                    \"li.item.product.product-item-info.product-item.col-12.col-xs-6.col-md-4.col-lg-3\")\n",
    "                \n",
    "                product_links = save_product_data(category_dir, products, actions)\n",
    "                \n",
    "                update_product_links(paths, product_links)\n",
    "                \n",
    "                try:\n",
    "                    next_page = driver.find_element(By.CSS_SELECTOR, \n",
    "                        \"div.bottom-pagination > div.toolbar.toolbar-products > div.pages.list-inline > ul.pagination > li.item.pages-item-next, \" +\n",
    "                        \"div.pager > div.pages.list-inline > ul.pagination > li.item.pages-item-next\")\n",
    "                    \n",
    "                    actions.move_to_element(next_page).click().perform()\n",
    "                    time.sleep(3) \n",
    "                except:\n",
    "                    print(f\"Đã hoàn thành cào danh mục: {category_name}\")\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "                    break\n",
    "    \n",
    "    print(\"Hoàn thành quá trình cào tất cả links sản phẩm\")\n",
    "    driver.quit()\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def crawl_details(paths):\n",
    "    \"\"\"\n",
    "    Hàm thực hiện việc cào chi tiết tất cả các sản phẩm từ list_add.csv\n",
    "    \"\"\"\n",
    "\n",
    "    list_add_path = paths['list_add_path']\n",
    "    list_done_path = paths['list_done_path']\n",
    "    \n",
    "    links_to_scrape = load_csv(list_add_path)\n",
    "    links_done = load_csv(list_done_path)\n",
    "    \n",
    "    links_to_scrape = links_to_scrape - links_done\n",
    "    \n",
    "    if not links_to_scrape:\n",
    "        print(\"Không có links mới cần cào chi tiết\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Bắt đầu cào chi tiết cho {len(links_to_scrape)} sản phẩm mới\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for i, link in enumerate(links_to_scrape):\n",
    "        print(f\"Cào chi tiết sản phẩm {i+1}/{len(links_to_scrape)}: {link}\")\n",
    "        success = scrape_product_detail(driver, link, paths)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"Hoàn thành cào chi tiết: {link}\")\n",
    "        else:\n",
    "            print(f\"Thất bại khi cào chi tiết: {link}\")\n",
    "        \n",
    "        time.sleep(1.5)\n",
    "    \n",
    "    print(f\"Hoàn thành cào chi tiết cho {len(links_to_scrape)} sản phẩm\")\n",
    "    driver.quit()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính thực hiện quá trình cào: \n",
    "    1. Cào tất cả links sản phẩm từ categories\n",
    "    2. Cào tất cả links sản phẩm từ collections\n",
    "    3. Sau đó cào chi tiết các sản phẩm\n",
    "    \"\"\"\n",
    "    print(\"Bắt đầu quá trình cào dữ liệu...\")\n",
    "    \n",
    "    print(\"=== PHASE 1: Crawling category ===\")\n",
    "    paths = crawl_links()\n",
    "    \n",
    "    print(\"=== PHASE 2: Crawling collection ===\")\n",
    "    crawl_collections()\n",
    "    \n",
    "    print(\"=== PHASE 3: Crawling product details ===\")\n",
    "    crawl_details(paths)\n",
    "    \n",
    "    print(\"Hoàn thành toàn bộ quá trình cào dữ liệu!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANTIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "prefs = {\n",
    "    \"credentials_enable_service\": False, \n",
    "    \"profile.password_manager_enabled\": False, \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# URL trang web\n",
    "web_url = \"https://www.pantio.vn/\"\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.maximize_window()\n",
    "driver.get(web_url)\n",
    "\n",
    "categorys = driver.find_elements(By.CSS_SELECTOR, \"li.megamenu a, li.dropdown a\")\n",
    "\n",
    "if categorys:\n",
    "    category = categorys[1] \n",
    "    category_href = category.get_attribute('href')\n",
    "\n",
    "    if 'collections' in category_href:\n",
    "        pattern = r\"collections/([^/?#]+)\"\n",
    "\n",
    "        match = re.search(pattern, category_href)\n",
    "        if match:\n",
    "            category_name = match.group(1).replace(\"-\", \"_\")\n",
    "            print(category_name) \n",
    "\n",
    "        print(f\"Opening: {category_href}\")\n",
    "\n",
    "        driver.execute_script(f\"window.open('{category_href}');\")\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        time.sleep(10)  \n",
    "\n",
    "        products = driver.find_elements(By.CSS_SELECTOR, \"div.grid__item.large--one-third.medium--one-third.small--one-half.md-pd-left15\")\n",
    "        product_links = []\n",
    "\n",
    "        os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "        for product in products:\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(product).perform()\n",
    "            time.sleep(5)\n",
    "            \n",
    "            product_element = product.find_element(By.CSS_SELECTOR, \"div.product-img a\")\n",
    "            product_href = product_element.get_attribute('href')\n",
    "            print(product_href)\n",
    "            product_links.append(product_href)\n",
    "\n",
    "            product_images = product.find_elements(By.CSS_SELECTOR, \"div.product-img img\")\n",
    "            image_counters = {}\n",
    "\n",
    "            for img in product_images:\n",
    "                img_url = img.get_attribute(\"src\")  \n",
    "                alt_text = img.get_attribute(\"alt\")  \n",
    "\n",
    "                clean_name = alt_text.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "                if clean_name not in image_counters:\n",
    "                    image_counters[clean_name] = 1  \n",
    "                else:\n",
    "                    image_counters[clean_name] += 1 \n",
    "\n",
    "                filename = os.path.join(\"images\", f\"{clean_name}_{image_counters[clean_name]}.jpg\")\n",
    "\n",
    "                response = requests.get(img_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(filename, \"wb\") as file:\n",
    "                        file.write(response.content)\n",
    "                    print(f\"Đã lưu: {filename}\")\n",
    "        while True:\n",
    "            try:\n",
    "                pagination = driver.find_element(By.CSS_SELECTOR, 'span.page.page-node.current')\n",
    "                pagination_text = pagination.text\n",
    "            except:\n",
    "                pagination_text = \"1\"\n",
    "            print(pagination_text)\n",
    "            try:\n",
    "                actions = ActionChains(driver)\n",
    "                next_page = driver.find_element(By.CSS_SELECTOR, 'span.nextPage')\n",
    "                actions.move_to_element(next_page).click().perform()\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv\n",
    "\n",
    "##### PATH + LINK #####\n",
    "\n",
    "base_save_dir = r'E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data'\n",
    "web_url = \"https://www.pantio.vn/\"\n",
    "\n",
    "##### FUNCTION TẠO THƯ MỤC #####\n",
    "\n",
    "def extract_website_name(url):\n",
    "    \"\"\"\n",
    "    Lấy tên website từ URL, ví dụ: 'https://www.pantio.vn/' -> 'pantio'\n",
    "    \"\"\"\n",
    "    match = re.search(r\"https?://(?:www\\.)?([^./]+)\", url)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "start_time = datetime.now()\n",
    "year = start_time.strftime(\"%Y\")\n",
    "month = start_time.strftime(\"%m\")\n",
    "day = start_time.strftime(\"%d\")\n",
    "hour_minute = start_time.strftime(\"%H_%M\")\n",
    "\n",
    "def initialize_directory_structure(base_save_dir, web_url):\n",
    "    \"\"\"\n",
    "    Tạo cấu trúc thư mục cơ bản theo yêu cầu:\n",
    "    website > năm > tháng > ngày > giờ_phút > list_view | detail_view | CSVs\n",
    "    \"\"\"\n",
    "    website_name = extract_website_name(web_url)\n",
    "    \n",
    "    website_dir = os.path.join(base_save_dir, website_name)\n",
    "    os.makedirs(website_dir, exist_ok=True)\n",
    "    \n",
    "    list_info_all_path = os.path.join(website_dir, \"list_info_all.csv\")\n",
    "    if not os.path.exists(list_info_all_path):\n",
    "        with open(list_info_all_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"url\"])  \n",
    "    \n",
    "    year_dir = os.path.join(website_dir, year)\n",
    "    month_dir = os.path.join(year_dir, month)\n",
    "    day_dir = os.path.join(month_dir, day)\n",
    "    time_dir = os.path.join(day_dir, hour_minute)\n",
    "    \n",
    "    os.makedirs(year_dir, exist_ok=True)\n",
    "    os.makedirs(month_dir, exist_ok=True)\n",
    "    os.makedirs(day_dir, exist_ok=True)\n",
    "    os.makedirs(time_dir, exist_ok=True)\n",
    "    \n",
    "    list_view_dir = os.path.join(time_dir, \"list_view\")\n",
    "    detail_view_dir = os.path.join(time_dir, \"detail_view\")\n",
    "    \n",
    "    os.makedirs(list_view_dir, exist_ok=True)\n",
    "    os.makedirs(detail_view_dir, exist_ok=True)\n",
    "    \n",
    "    list_attempt_path = os.path.join(time_dir, \"list_attempt.csv\")\n",
    "    list_add_path = os.path.join(time_dir, \"list_add.csv\")\n",
    "    list_done_path = os.path.join(time_dir, \"list_done.csv\")\n",
    "    detail_attempt_path = os.path.join(time_dir, \"detail_attempt.csv\")\n",
    "    \n",
    "    for path in [list_attempt_path, list_add_path, list_done_path]:\n",
    "        if not os.path.exists(path):\n",
    "            with open(path, 'w', encoding='utf-8', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"url\"]) \n",
    "    \n",
    "    if not os.path.exists(detail_attempt_path):\n",
    "        with open(detail_attempt_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"sku\", \"name\", \"original_price\", \"sale_price\", \"colors\", \"sizes\", \"description\", \"url\", \"images\"])\n",
    "    \n",
    "    print(f\"Initialized directory structure for {website_name}\")\n",
    "    \n",
    "    return {\n",
    "        'website_dir': website_dir,\n",
    "        'time_dir': time_dir,\n",
    "        'list_view_dir': list_view_dir,\n",
    "        'detail_view_dir': detail_view_dir,\n",
    "        'list_attempt_path': list_attempt_path,\n",
    "        'list_add_path': list_add_path,\n",
    "        'list_done_path': list_done_path,\n",
    "        'detail_attempt_path': detail_attempt_path,\n",
    "        'list_info_all_path': list_info_all_path\n",
    "    }\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\"Hàm để đọc dữ liệu từ file CSV và trả về một set.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader, None)  \n",
    "        return {row[0] for row in reader if row and row[0] != \"url\"}\n",
    "\n",
    "def append_csv(file_path, data):\n",
    "    \"\"\"Hàm để lưu dữ liệu vào file CSV theo kiểu append.\"\"\"\n",
    "    file_exists = os.path.isfile(file_path) and os.path.getsize(file_path) > 0\n",
    "    \n",
    "    with open(file_path, \"a\", encoding=\"utf-8\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"url\"])\n",
    "        for item in data:\n",
    "            writer.writerow([item])\n",
    "\n",
    "def update_product_links(paths, product_links):\n",
    "    \"\"\"\n",
    "    Cập nhật các file CSV theo quy trình:\n",
    "    - So sánh list_attempt với list_info_all để tìm ra các links mới (list_add)\n",
    "    - Thêm các links mới vào list_info_all và list_add\n",
    "    - Thêm tất cả các links vào list_attempt\n",
    "    \"\"\"\n",
    "    list_info_all = load_csv(paths['list_info_all_path'])\n",
    "    list_attempt = set(product_links) \n",
    "    \n",
    "    list_add = list_attempt - list_info_all\n",
    "    \n",
    "    if list_add:\n",
    "        append_csv(paths['list_info_all_path'], list_add)\n",
    "        append_csv(paths['list_add_path'], list_add)\n",
    "    \n",
    "    append_csv(paths['list_attempt_path'], list_attempt)\n",
    "    \n",
    "    print(f\"Updated CSV files:\")\n",
    "    print(f\"- Added {len(list_add)} new links to list_add.csv\")\n",
    "    print(f\"- Added {len(list_attempt)} links to list_attempt.csv\")\n",
    "    \n",
    "    return list_add\n",
    "\n",
    "def create_category_directory(list_view_dir, category_name, pagination_text):\n",
    "    \"\"\"\n",
    "    Tạo thư mục category_{pagination} trong list_view\n",
    "    \"\"\"\n",
    "    category_dir = os.path.join(list_view_dir, f\"{category_name}_{pagination_text}\")\n",
    "    images_dir = os.path.join(category_dir, \"images\")\n",
    "    \n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Created category directory: {category_dir}\")\n",
    "    \n",
    "    return category_dir, images_dir\n",
    "\n",
    "def create_detail_directory(detail_view_dir, sku, product_name):\n",
    "    \"\"\"\n",
    "    Tạo thư mục trong detail_view theo cấu trúc:\n",
    "    part_X > {năm_tháng_ngày_giờ_phút}_{sku}_{name}\n",
    "    \"\"\"\n",
    "    part_folders = [f for f in os.listdir(detail_view_dir) if f.startswith(\"part_\")]\n",
    "    \n",
    "    if not part_folders:\n",
    "        part_folder = os.path.join(detail_view_dir, \"part_1\")\n",
    "        os.makedirs(part_folder, exist_ok=True)\n",
    "    else:\n",
    "        part_folder = os.path.join(detail_view_dir, sorted(part_folders)[-1])\n",
    "        if len(os.listdir(part_folder)) >= 300:\n",
    "            part_num = len(part_folders) + 1\n",
    "            part_folder = os.path.join(detail_view_dir, f\"part_{part_num}\")\n",
    "            os.makedirs(part_folder, exist_ok=True)\n",
    "    \n",
    "    clean_product_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", product_name.replace(\" \", \"_\"))\n",
    "    \n",
    "    timestamp = f\"{year}_{month}_{day}_{hour_minute}\"\n",
    "    item_folder = os.path.join(part_folder, f\"{timestamp}_{sku}_{clean_product_name}\")\n",
    "    os.makedirs(item_folder, exist_ok=True)\n",
    "    \n",
    "    image_folder = os.path.join(item_folder, \"images\")\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    \n",
    "    return item_folder, image_folder\n",
    "\n",
    "def save_html_source(folder_path, driver, filename=\"html.txt\"):\n",
    "    \"\"\"Lưu source HTML của trang hiện tại vào file.\"\"\"\n",
    "    html_content = driver.page_source\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "    print(f\"Saved HTML: {file_path}\")\n",
    "\n",
    "def save_product_data(folder_path, products, actions):\n",
    "    \"\"\"Lưu dữ liệu sản phẩm từ list view và trả về danh sách các links.\"\"\"\n",
    "    image_folder = os.path.join(folder_path, \"images\")\n",
    "    \n",
    "    product_links = []\n",
    "    \n",
    "    for product in products:\n",
    "        try:\n",
    "            actions.move_to_element(product).perform()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            product_element = product.find_element(By.CSS_SELECTOR, \"div.product-img a\")\n",
    "            product_href = product_element.get_attribute('href')\n",
    "            product_links.append(product_href)\n",
    "            \n",
    "            product_images = product.find_elements(By.CSS_SELECTOR, \"div.product-img img\")\n",
    "            image_counters = {}\n",
    "            \n",
    "            for img in product_images:\n",
    "                img_url = img.get_attribute(\"src\")\n",
    "                if \"data:image\" in img_url:  \n",
    "                    img_url = img.get_attribute(\"data-src\")\n",
    "                    \n",
    "                if not img_url or \"data:image\" in img_url:\n",
    "                    continue\n",
    "                \n",
    "                alt_text = img.get_attribute(\"alt\") or f\"product_{len(product_links)}\"\n",
    "                clean_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", alt_text.replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "                \n",
    "                if clean_name not in image_counters:\n",
    "                    image_counters[clean_name] = 1\n",
    "                else:\n",
    "                    image_counters[clean_name] += 1\n",
    "                \n",
    "                image_name = f\"{clean_name}_{image_counters[clean_name]}.jpg\"\n",
    "                image_path = os.path.join(image_folder, image_name)\n",
    "                \n",
    "                try:\n",
    "                    response = requests.get(img_url)\n",
    "                    if response.status_code == 200:\n",
    "                        with open(image_path, \"wb\") as file:\n",
    "                            file.write(response.content)\n",
    "                        print(f\"Saved Image: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving image {img_url}: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "    \n",
    "    json_path = os.path.join(folder_path, \"data.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(product_links, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saved JSON with {len(product_links)} product links: {json_path}\")\n",
    "    \n",
    "    return product_links\n",
    "\n",
    "def scrape_product_detail(driver, product_url, paths):\n",
    "    \"\"\"\n",
    "    Lấy chi tiết sản phẩm từ trang detail của Pantio và lưu vào thư mục tương ứng.\n",
    "    Cập nhật list_done.csv và detail_attempt.csv\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(product_url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        try: \n",
    "            sku_element = driver.find_element(By.CSS_SELECTOR, 'div.pro-sku span.sku-number')\n",
    "            sku_value = sku_element.text.strip()\n",
    "            time.sleep(1)\n",
    "        except: \n",
    "            sku_value = f\"unknown_sku_{int(time.time())}\"\n",
    "            print(\"Không tìm thấy SKU, sử dụng mã tạm thời\")\n",
    "        \n",
    "        try:\n",
    "            name_element = driver.find_element(By.CSS_SELECTOR, 'h1[itemprop=\"name\"]')\n",
    "            name_value = name_element.text.strip()\n",
    "            time.sleep(1)\n",
    "        except: \n",
    "            name_value = f\"Unknown Product {int(time.time())}\"\n",
    "            print(\"Không tìm thấy tên sản phẩm, sử dụng tên tạm thời\")\n",
    "        \n",
    "        try:\n",
    "            price_element = driver.find_element(By.CSS_SELECTOR, 'div.pro-price.clearfix span.original-price.ComparePrice')\n",
    "            original_price_value = price_element.text.strip()\n",
    "            \n",
    "            sale_element = driver.find_element(By.CSS_SELECTOR, 'div.pro-price.clearfix span.current-price.ProductPrice')\n",
    "            sale_price_value = sale_element.text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                price_element = driver.find_element(By.CSS_SELECTOR, 'div.pro-price.clearfix span.current-price.ProductPrice')\n",
    "                original_price_value = price_element.text.strip()\n",
    "                sale_price_value = None\n",
    "            except:\n",
    "                original_price_value = None\n",
    "                sale_price_value = None\n",
    "                print(\"Không tìm thấy thông tin giá\")\n",
    "        \n",
    "        try:\n",
    "            swatch_element = driver.find_element(By.ID, 'variant-swatch-0')\n",
    "            color_elements = swatch_element.find_elements(By.CSS_SELECTOR, '.swatch-element')\n",
    "            colors_value = [element.get_attribute('data-value') for element in color_elements]\n",
    "            colors_string = \"_\".join(colors_value)\n",
    "        except:\n",
    "            colors_value = []\n",
    "            colors_string = None\n",
    "            print(\"Không tìm thấy thông tin màu sắc\")\n",
    "        \n",
    "        try: \n",
    "            swatch_element = driver.find_element(By.ID, 'variant-swatch-1')\n",
    "            size_elements = swatch_element.find_elements(By.CSS_SELECTOR, '.swatch-element')\n",
    "            sizes_value = [element.get_attribute('data-value') for element in size_elements]\n",
    "            sizes_string = \"_\".join(sizes_value)\n",
    "        except:\n",
    "            sizes_value = []\n",
    "            sizes_string = None\n",
    "            print(\"Không tìm thấy thông tin kích thước\")\n",
    "        \n",
    "        try:\n",
    "            description_element = driver.find_element(By.CSS_SELECTOR, 'div.pro-short-desc')\n",
    "            description_value = description_element.text.strip().replace(\"\\n\", \" _ \")\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            description_value = None\n",
    "            print(\"Không tìm thấy mô tả sản phẩm\")\n",
    "        \n",
    "        image_urls = []\n",
    "        try:\n",
    "            list_image_element = driver.find_element(By.CSS_SELECTOR, 'div.slick-list.draggable')\n",
    "            image_elements = list_image_element.find_elements(By.CSS_SELECTOR, 'li.product-gallery.slick-slide img.product-image-feature2')\n",
    "            \n",
    "            for image_element in image_elements:\n",
    "                image_url = image_element.get_attribute('src')\n",
    "                if image_url and \"data:image\" not in image_url:\n",
    "                    image_urls.append(image_url)\n",
    "                    \n",
    "            if not image_urls:\n",
    "                image_elements = driver.find_elements(By.CSS_SELECTOR, 'div.product-gallery img')\n",
    "                for image_element in image_elements:\n",
    "                    image_url = image_element.get_attribute('src')\n",
    "                    if image_url and \"data:image\" not in image_url:\n",
    "                        image_urls.append(image_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi lấy ảnh sản phẩm: {e}\")\n",
    "        \n",
    "        item_folder, image_folder = create_detail_directory(\n",
    "            paths['detail_view_dir'], \n",
    "            sku_value, \n",
    "            name_value\n",
    "        )\n",
    "        \n",
    "        save_html_source(item_folder, driver)\n",
    "        \n",
    "        product_data = {\n",
    "            \"sku\": sku_value,\n",
    "            \"name\": name_value,\n",
    "            \"original_price\": original_price_value,\n",
    "            \"sale_price\": sale_price_value,\n",
    "            \"colors\": colors_string,\n",
    "            \"sizes\": sizes_string,\n",
    "            \"description\": description_value,\n",
    "            \"url\": product_url,\n",
    "            \"images\": image_urls\n",
    "        }\n",
    "        \n",
    "        json_path = os.path.join(item_folder, \"data.json\")\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(product_data, json_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        for idx, image_url in enumerate(image_urls, start=1):\n",
    "            image_name = f\"{sku_value}_{idx:02}.jpg\"\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(image_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(image_path, \"wb\") as file:\n",
    "                        file.write(response.content)\n",
    "                    print(f\"Saved Image: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving image {image_url}: {e}\")\n",
    "        \n",
    "        append_csv(paths['list_done_path'], [product_url])\n",
    "        \n",
    "        detail_attempt_exists = os.path.isfile(paths['detail_attempt_path']) and os.path.getsize(paths['detail_attempt_path']) > 0\n",
    "        \n",
    "        with open(paths['detail_attempt_path'], \"a\", encoding=\"utf-8\", newline='') as f:\n",
    "            fieldnames = [\"sku\", \"name\", \"original_price\", \"sale_price\", \"colors\", \"sizes\", \"description\", \"url\", \"images\"]\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            \n",
    "            if not detail_attempt_exists:\n",
    "                writer.writeheader()\n",
    "            \n",
    "            data_to_write = product_data.copy()\n",
    "            data_to_write[\"images\"] = json.dumps(product_data[\"images\"], ensure_ascii=False)\n",
    "            \n",
    "            writer.writerow(data_to_write)\n",
    "        \n",
    "        print(f\"Successfully scraped product: {name_value} ({sku_value})\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {product_url}: {e}\")\n",
    "        return False\n",
    "\n",
    "##### CHẶN THÔNG BÁO #####\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "prefs = {\n",
    "    \"credentials_enable_service\": False, \n",
    "    \"profile.password_manager_enabled\": False, \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "##### MAIN FUNCTION #####\n",
    "\n",
    "def crawl_links():\n",
    "    \"\"\"\n",
    "    Hàm thực hiện việc cào tất cả các links sản phẩm từ Pantio\n",
    "    \"\"\"\n",
    "    paths = initialize_directory_structure(base_save_dir, web_url)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver.get(web_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    categorys = driver.find_elements(By.CSS_SELECTOR, \"li.megamenu a, li.dropdown a\")\n",
    "    \n",
    "    for index, category in enumerate(categorys):\n",
    "        if index >= 3:\n",
    "            break\n",
    "        category_href = category.get_attribute('href')\n",
    "        if 'collections' in category_href:\n",
    "            pattern = r\"collections/([^/?#]+)\"\n",
    "            match = re.search(pattern, category_href)\n",
    "            if match:\n",
    "                category_name = match.group(1).replace(\"-\", \"_\")\n",
    "            else:\n",
    "                category_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", category_href.replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "            \n",
    "            print(f\"Opening: {category_href} (Category: {category_name})\")\n",
    "            \n",
    "            driver.execute_script(f\"window.open('{category_href}');\")\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            time.sleep(5)\n",
    "            \n",
    "            has_next_page = True\n",
    "            \n",
    "            while has_next_page:\n",
    "                try:\n",
    "                    pagination = driver.find_element(By.CSS_SELECTOR, 'span.page.page-node.current')\n",
    "                    pagination_text = pagination.text\n",
    "                except:\n",
    "                    pagination_text = \"1\"\n",
    "                \n",
    "                print(f\"Processing: {category_name} - Page {pagination_text}\")\n",
    "                \n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(3)\n",
    "                \n",
    "                category_dir, _ = create_category_directory(paths['list_view_dir'], category_name, pagination_text)\n",
    "                \n",
    "                save_html_source(category_dir, driver)\n",
    "                \n",
    "                products = driver.find_elements(By.CSS_SELECTOR, \"div.grid__item.large--one-third.medium--one-third.small--one-half.md-pd-left15\")\n",
    "                \n",
    "                if not products:\n",
    "                    products = driver.find_elements(By.CSS_SELECTOR, \"div.product-item\")\n",
    "                \n",
    "                if products:\n",
    "                    product_links = save_product_data(category_dir, products, actions)\n",
    "                    \n",
    "                    update_product_links(paths, product_links)\n",
    "                else:\n",
    "                    print(f\"Không tìm thấy sản phẩm nào trong trang {pagination_text}\")\n",
    "                \n",
    "                try:\n",
    "                    next_page = driver.find_element(By.CSS_SELECTOR, \"span.nextPage\")\n",
    "                    actions.move_to_element(next_page).click().perform()\n",
    "                    time.sleep(5) \n",
    "                except Exception as e:\n",
    "                    print(f\"Không tìm thấy nút next page hoặc đã hết trang: {e}\")\n",
    "                    has_next_page = False\n",
    "            \n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            \n",
    "    driver.quit()\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def crawl_details(paths):\n",
    "    \"\"\"\n",
    "    Hàm thực hiện việc cào chi tiết tất cả các sản phẩm từ list_add.csv\n",
    "    \"\"\"\n",
    "    list_add_path = paths['list_add_path']\n",
    "    list_done_path = paths['list_done_path']\n",
    "    \n",
    "    links_to_scrape = load_csv(list_add_path)\n",
    "    links_done = load_csv(list_done_path)\n",
    "    \n",
    "    links_to_scrape = links_to_scrape - links_done\n",
    "    \n",
    "    if not links_to_scrape:\n",
    "        print(\"Không có links mới cần cào chi tiết\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Bắt đầu cào chi tiết cho {len(links_to_scrape)} sản phẩm mới\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for i, link in enumerate(links_to_scrape):\n",
    "        print(f\"Cào chi tiết sản phẩm {i+1}/{len(links_to_scrape)}: {link}\")\n",
    "        success = scrape_product_detail(driver, link, paths)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"Hoàn thành cào chi tiết: {link}\")\n",
    "        else:\n",
    "            print(f\"Thất bại khi cào chi tiết: {link}\")\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"Hoàn thành cào chi tiết cho {len(links_to_scrape)} sản phẩm\")\n",
    "    driver.quit()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính thực hiện quá trình cào: \n",
    "    1. Cào tất cả links sản phẩm từ categories\n",
    "    2. Sau đó cào chi tiết các sản phẩm\n",
    "    \"\"\"\n",
    "    print(\"Bắt đầu quá trình cào dữ liệu...\")\n",
    "    \n",
    "    print(\"=== PHASE 1: Crawling category ===\")\n",
    "    paths = crawl_links()\n",
    "    \n",
    "    \n",
    "    print(\"=== PHASE 2: Crawling product details ===\")\n",
    "    crawl_details(paths)\n",
    "    \n",
    "    print(\"Hoàn thành toàn bộ quá trình cào dữ liệu!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IVYMODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "prefs = {\n",
    "    \"credentials_enable_service\": False, \n",
    "    \"profile.password_manager_enabled\": False, \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# URL trang web\n",
    "web_url = \"https://ivymoda.com/\"\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.maximize_window()\n",
    "driver.get(web_url)\n",
    "\n",
    "\n",
    "# Xóa thông báo \n",
    "try:  \n",
    "    close_button = driver.find_element(By.CSS_SELECTOR, \"div.popup-content div.action-close\")\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(close_button).click().perform()\n",
    "except:\n",
    "        print(\"Không có thông báo nào.\")  \n",
    "\n",
    "\n",
    "actions = ActionChains(driver)\n",
    "menu_element = driver.find_element(By.CSS_SELECTOR, \"ul.menu\")\n",
    "categorys = menu_element.find_elements(By.TAG_NAME, \"a\")\n",
    "for category in categorys: \n",
    "    category_href = category.get_attribute('href')\n",
    "    if 'danh-muc' in category_href or 'lookbook' in category_href:\n",
    "\n",
    "        pattern = r\"(?:danh-muc|lookbook)/([^/?#]+)\"\n",
    "        match = re.search(pattern, category_href)\n",
    "        if match:\n",
    "            category_name = match.group(1).replace(\"-\", \"_\")\n",
    "\n",
    "        print(category_name)\n",
    "        print(category_href)\n",
    "        # driver.execute_script(f\"window.open('{category_href}');\")\n",
    "        # driver.switch_to.window(driver.window_handles[-1])\n",
    "        # time.sleep(10)\n",
    "\n",
    "        # os.makedirs(\"images\", exist_ok=True)\n",
    "        # products = driver.find_elements(By.CSS_SELECTOR, \"div.item-cat-product div.product div.thumb-product a\")\n",
    "        # for product in products: \n",
    "        #     actions.move_to_element(product).perform()\n",
    "        #     product_href = product.get_attribute('href')\n",
    "        #     print(product_href)\n",
    "\n",
    "        #     product_images = product.find_elements(By.CSS_SELECTOR, \"div.item-cat-product div.product div.thumb-product img\")\n",
    "        #     image_counters = {}\n",
    "        #     for img in product_images:\n",
    "        #         img_url = img.get_attribute(\"src\") or img.get_attribute(\"data-original\")\n",
    "        #         alt_text = img.get_attribute(\"alt\")  \n",
    "\n",
    "        #         clean_name = alt_text.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "        #         if clean_name not in image_counters:\n",
    "        #             image_counters[clean_name] = 1  \n",
    "        #         else:\n",
    "        #             image_counters[clean_name] += 1 \n",
    "\n",
    "        #         filename = os.path.join(\"images\", f\"{clean_name}_{image_counters[clean_name]}.jpg\")\n",
    "\n",
    "        #         response = requests.get(img_url)\n",
    "        #         if response.status_code == 200:\n",
    "        #             with open(filename, \"wb\") as file:\n",
    "        #                 file.write(response.content)\n",
    "        #             print(f\"Đã lưu: {filename}\")\n",
    "\n",
    "        # while True:\n",
    "        #     try:\n",
    "        #         pagination = driver.find_element(\"xpath\", '//*[@id=\"products_active_ts\"]')\n",
    "        #         pagination_text = pagination.text\n",
    "        #     except:\n",
    "        #         pagination_text = \"1\"\n",
    "        #     print(pagination_text)\n",
    "        #     try:\n",
    "        #         actions = ActionChains(driver)\n",
    "        #         next_page = driver.find_element(\"xpath\", '//li[@class=\"last-page\"]/preceding-sibling::li[1]')\n",
    "        #         actions.move_to_element(next_page).click().perform()\n",
    "        #         time.sleep(5)\n",
    "        #     except:\n",
    "        #         driver.close()\n",
    "        #         driver.switch_to.window(driver.window_handles[0])\n",
    "        #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv\n",
    "\n",
    "##### PATH + LINK #####\n",
    "\n",
    "base_save_dir = r'E:\\INTERN\\PORTFOLIO\\AUTOMATION\\SYSTEM\\data'\n",
    "web_url = \"https://ivymoda.com/\"\n",
    "\n",
    "##### FUNCTION TẠO THƯ MỤC #####\n",
    "\n",
    "def extract_website_name(url):\n",
    "    \"\"\"\n",
    "    Lấy tên website từ URL, ví dụ: 'https://ivymoda.com/' -> 'ivymoda'\n",
    "    \"\"\"\n",
    "    match = re.search(r\"https?://(?:www\\.)?([^./]+)\", url)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "start_time = datetime.now()\n",
    "year = start_time.strftime(\"%Y\")\n",
    "month = start_time.strftime(\"%m\")\n",
    "day = start_time.strftime(\"%d\")\n",
    "hour_minute = start_time.strftime(\"%H_%M\")\n",
    "\n",
    "def initialize_directory_structure(base_save_dir, web_url):\n",
    "    \"\"\"\n",
    "    Tạo cấu trúc thư mục cơ bản theo yêu cầu:\n",
    "    website > năm > tháng > ngày > giờ_phút > list_view | detail_view | CSVs\n",
    "    \"\"\"\n",
    "    website_name = extract_website_name(web_url)\n",
    "    \n",
    "    website_dir = os.path.join(base_save_dir, website_name)\n",
    "    os.makedirs(website_dir, exist_ok=True)\n",
    "    \n",
    "    list_info_all_path = os.path.join(website_dir, \"list_info_all.csv\")\n",
    "    if not os.path.exists(list_info_all_path):\n",
    "        with open(list_info_all_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"url\"])  \n",
    "    \n",
    "    year_dir = os.path.join(website_dir, year)\n",
    "    month_dir = os.path.join(year_dir, month)\n",
    "    day_dir = os.path.join(month_dir, day)\n",
    "    time_dir = os.path.join(day_dir, hour_minute)\n",
    "    \n",
    "    os.makedirs(year_dir, exist_ok=True)\n",
    "    os.makedirs(month_dir, exist_ok=True)\n",
    "    os.makedirs(day_dir, exist_ok=True)\n",
    "    os.makedirs(time_dir, exist_ok=True)\n",
    "    \n",
    "    list_view_dir = os.path.join(time_dir, \"list_view\")\n",
    "    detail_view_dir = os.path.join(time_dir, \"detail_view\")\n",
    "    \n",
    "    os.makedirs(list_view_dir, exist_ok=True)\n",
    "    os.makedirs(detail_view_dir, exist_ok=True)\n",
    "    \n",
    "    list_attempt_path = os.path.join(time_dir, \"list_attempt.csv\")\n",
    "    list_add_path = os.path.join(time_dir, \"list_add.csv\")\n",
    "    list_done_path = os.path.join(time_dir, \"list_done.csv\")\n",
    "    detail_attempt_path = os.path.join(time_dir, \"detail_attempt.csv\")\n",
    "    \n",
    "    for path in [list_attempt_path, list_add_path, list_done_path]:\n",
    "        if not os.path.exists(path):\n",
    "            with open(path, 'w', encoding='utf-8', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"url\"]) \n",
    "    \n",
    "    if not os.path.exists(detail_attempt_path):\n",
    "        with open(detail_attempt_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"sku\", \"name\", \"original_price\", \"sale_price\", \"sizes\", \"colors\", \"description\", \"url\", \"images\"])\n",
    "    \n",
    "    print(f\"Initialized directory structure for {website_name}\")\n",
    "    \n",
    "    return {\n",
    "        'website_dir': website_dir,\n",
    "        'time_dir': time_dir,\n",
    "        'list_view_dir': list_view_dir,\n",
    "        'detail_view_dir': detail_view_dir,\n",
    "        'list_attempt_path': list_attempt_path,\n",
    "        'list_add_path': list_add_path,\n",
    "        'list_done_path': list_done_path,\n",
    "        'detail_attempt_path': detail_attempt_path,\n",
    "        'list_info_all_path': list_info_all_path\n",
    "    }\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\"Hàm để đọc dữ liệu từ file CSV và trả về một set.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader, None)  # Skip header row\n",
    "        return {row[0] for row in reader if row and row[0] != \"url\"}\n",
    "\n",
    "def append_csv(file_path, data):\n",
    "    \"\"\"Hàm để lưu dữ liệu vào file CSV theo kiểu append.\"\"\"\n",
    "    file_exists = os.path.isfile(file_path) and os.path.getsize(file_path) > 0\n",
    "    \n",
    "    with open(file_path, \"a\", encoding=\"utf-8\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"url\"])\n",
    "        for item in data:\n",
    "            writer.writerow([item])\n",
    "\n",
    "def update_product_links(paths, product_links):\n",
    "    \"\"\"\n",
    "    Cập nhật các file CSV theo quy trình:\n",
    "    - So sánh list_attempt với list_info_all để tìm ra các links mới (list_add)\n",
    "    - Thêm các links mới vào list_info_all và list_add\n",
    "    - Thêm tất cả các links vào list_attempt\n",
    "    \"\"\"\n",
    "    list_info_all = load_csv(paths['list_info_all_path'])\n",
    "    list_attempt = set(product_links) \n",
    "    \n",
    "    list_add = list_attempt - list_info_all\n",
    "    \n",
    "    if list_add:\n",
    "        append_csv(paths['list_info_all_path'], list_add)\n",
    "        append_csv(paths['list_add_path'], list_add)\n",
    "    \n",
    "    append_csv(paths['list_attempt_path'], list_attempt)\n",
    "    \n",
    "    print(f\"Updated CSV files:\")\n",
    "    print(f\"- Added {len(list_add)} new links to list_add.csv\")\n",
    "    print(f\"- Added {len(list_attempt)} links to list_attempt.csv\")\n",
    "    \n",
    "    return list_add\n",
    "\n",
    "def create_category_directory(list_view_dir, category_name, pagination_text):\n",
    "    \"\"\"\n",
    "    Tạo thư mục category_{pagination} trong list_view\n",
    "    \"\"\"\n",
    "    category_dir = os.path.join(list_view_dir, f\"{category_name}_{pagination_text}\")\n",
    "    images_dir = os.path.join(category_dir, \"images\")\n",
    "    \n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Created category directory: {category_dir}\")\n",
    "    \n",
    "    return category_dir, images_dir\n",
    "\n",
    "def create_detail_directory(detail_view_dir, sku, product_name):\n",
    "    \"\"\"\n",
    "    Tạo thư mục trong detail_view theo cấu trúc:\n",
    "    part_X > {năm_tháng_ngày_giờ_phút}_{sku}_{name}\n",
    "    \"\"\"\n",
    "    part_folders = [f for f in os.listdir(detail_view_dir) if f.startswith(\"part_\")]\n",
    "    \n",
    "    if not part_folders:\n",
    "        part_folder = os.path.join(detail_view_dir, \"part_1\")\n",
    "        os.makedirs(part_folder, exist_ok=True)\n",
    "    else:\n",
    "        part_folder = os.path.join(detail_view_dir, sorted(part_folders)[-1])\n",
    "        if len(os.listdir(part_folder)) >= 300:\n",
    "            part_num = len(part_folders) + 1\n",
    "            part_folder = os.path.join(detail_view_dir, f\"part_{part_num}\")\n",
    "            os.makedirs(part_folder, exist_ok=True)\n",
    "    \n",
    "    clean_product_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", product_name.replace(\" \", \"_\"))\n",
    "    \n",
    "    timestamp = f\"{year}_{month}_{day}_{hour_minute}\"\n",
    "    item_folder = os.path.join(part_folder, f\"{timestamp}_{sku}_{clean_product_name}\")\n",
    "    os.makedirs(item_folder, exist_ok=True)\n",
    "    \n",
    "    image_folder = os.path.join(item_folder, \"images\")\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    \n",
    "    return item_folder, image_folder\n",
    "\n",
    "def save_html_source(folder_path, driver, filename=\"html.txt\"):\n",
    "    \"\"\"Lưu source HTML của trang hiện tại vào file.\"\"\"\n",
    "    html_content = driver.page_source\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "    print(f\"Saved HTML: {file_path}\")\n",
    "\n",
    "def save_product_data(folder_path, products, actions):\n",
    "    \"\"\"Lưu dữ liệu sản phẩm từ list view của IvyModa và trả về danh sách các links.\"\"\"\n",
    "    image_folder = os.path.join(folder_path, \"images\")\n",
    "    \n",
    "    product_links = []\n",
    "    \n",
    "    for product in products:\n",
    "        try:\n",
    "            actions.move_to_element(product).perform()\n",
    "            \n",
    "            # Lấy link sản phẩm từ IvyModa\n",
    "            product_href = product.get_attribute('href')\n",
    "            if product_href:\n",
    "                product_links.append(product_href)\n",
    "                \n",
    "                # Lấy và lưu ảnh sản phẩm\n",
    "                parent_product = product.find_element(By.XPATH, \"./..\")\n",
    "                product_images = parent_product.find_elements(By.CSS_SELECTOR, \"img\")\n",
    "                \n",
    "                image_counters = {}\n",
    "                \n",
    "                for img in product_images:\n",
    "                    img_url = img.get_attribute(\"src\") or img.get_attribute(\"data-original\")\n",
    "                    if not img_url or \"data:image\" in img_url:\n",
    "                        continue\n",
    "                    \n",
    "                    alt_text = img.get_attribute(\"alt\") or f\"product_{len(product_links)}\"\n",
    "                    clean_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", alt_text.replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "                    \n",
    "                    if clean_name not in image_counters:\n",
    "                        image_counters[clean_name] = 1\n",
    "                    else:\n",
    "                        image_counters[clean_name] += 1\n",
    "                    \n",
    "                    image_name = f\"{clean_name}_{image_counters[clean_name]}.jpg\"\n",
    "                    image_path = os.path.join(image_folder, image_name)\n",
    "                    \n",
    "                    try:\n",
    "                        response = requests.get(img_url)\n",
    "                        if response.status_code == 200:\n",
    "                            with open(image_path, \"wb\") as file:\n",
    "                                file.write(response.content)\n",
    "                            print(f\"Saved Image: {image_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving image {img_url}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "    \n",
    "    # Lưu danh sách links vào file JSON\n",
    "    json_path = os.path.join(folder_path, \"data.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(product_links, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saved JSON with {len(product_links)} product links: {json_path}\")\n",
    "    \n",
    "    return product_links\n",
    "\n",
    "def scrape_product_detail(driver, product_url, paths):\n",
    "    \"\"\"\n",
    "    Lấy chi tiết sản phẩm từ trang detail của IvyModa và lưu vào thư mục tương ứng.\n",
    "    Cập nhật list_done.csv và detail_attempt.csv\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(product_url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Khởi tạo ActionChains\n",
    "        actions = ActionChains(driver)\n",
    "        \n",
    "        # Lấy mã sản phẩm (SKU)\n",
    "        try: \n",
    "            sku_element = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__sub-info p span')\n",
    "            sku_value = sku_element.text.strip()\n",
    "            time.sleep(1)\n",
    "        except Exception as e: \n",
    "            print(f\"Error getting SKU: {e}\")\n",
    "            sku_value = f\"unknown_sku_{int(time.time())}\"\n",
    "        \n",
    "        # Lấy tên sản phẩm\n",
    "        try:\n",
    "            name_element = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__information h1')\n",
    "            name_value = name_element.text.strip()\n",
    "            time.sleep(1)\n",
    "        except Exception as e: \n",
    "            print(f\"Error getting name: {e}\")\n",
    "            name_value = f\"Unknown Product {int(time.time())}\"\n",
    "        \n",
    "        # Lấy giá gốc và giá khuyến mãi\n",
    "        try:\n",
    "            price_element = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__price del')\n",
    "            original_price_value = price_element.text.strip()\n",
    "            \n",
    "            sale_element = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__price b')\n",
    "            sale_price_value = sale_element.text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                price_element = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__price b')\n",
    "                original_price_value = price_element.text.strip()\n",
    "                sale_price_value = None\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting price: {e}\")\n",
    "                original_price_value = None\n",
    "                sale_price_value = None\n",
    "        \n",
    "        # Lấy thông tin kích thước\n",
    "        try:\n",
    "            size_elements = driver.find_elements(By.CSS_SELECTOR, 'div.product-detail__size__input span.text-uppercase')\n",
    "            sizes_value = [element.text for element in size_elements]\n",
    "            sizes_string = \"_\".join(sizes_value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting sizes: {e}\")\n",
    "            sizes_value = []\n",
    "            sizes_string = None\n",
    "        \n",
    "        # Lấy mô tả sản phẩm\n",
    "        introduction_value = []\n",
    "        try:\n",
    "            description_buttons = driver.find_elements(By.CSS_SELECTOR, 'div.product-detail__tab div.product-detail__tab-header div.tab-item')\n",
    "            for description_button in description_buttons: \n",
    "                actions.move_to_element(description_button).click().perform()\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # Thử nhấn nút \"Xem thêm\" nếu có\n",
    "                try:\n",
    "                    show_more_button = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__tab div.product-detail__tab-body div.show-more a')\n",
    "                    actions.move_to_element(show_more_button).click().perform()\n",
    "                    time.sleep(2)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                introduction_element = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__tab-body div.tab-content.active.showContent')\n",
    "                \n",
    "                p_elements = introduction_element.find_elements(By.TAG_NAME, 'p')\n",
    "                tr_elements = introduction_element.find_elements(By.TAG_NAME, 'tr')                \n",
    "                all_elements = p_elements + tr_elements\n",
    "                \n",
    "                value = [element.text for element in all_elements]\n",
    "                introduction_value.extend(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting description: {e}\")\n",
    "        \n",
    "        description_value = \" _ \".join([text for text in introduction_value if text.strip()]) if introduction_value else None\n",
    "        \n",
    "        # Lấy thông tin màu sắc và hình ảnh\n",
    "        color_values = []\n",
    "        image_urls = []\n",
    "        \n",
    "        try: \n",
    "            # Trước tiên, lấy ảnh từ trang hiện tại\n",
    "            image_elements_current = driver.find_elements(By.CSS_SELECTOR, 'div.product-detail__gallery img.lazyloaded, div.product-detail__gallery img')\n",
    "            for image_element in image_elements_current:\n",
    "                image_url = image_element.get_attribute('src') or image_element.get_attribute('data-src')\n",
    "                if image_url and not \"data:image\" in image_url and image_url not in image_urls:\n",
    "                    image_urls.append(image_url)\n",
    "            \n",
    "            # Sau đó kiểm tra các màu khác\n",
    "            button_color_elements = driver.find_elements(By.CSS_SELECTOR, 'div.product-detail__color div.product-detail__color__input label span a')\n",
    "            for button_color_element in button_color_elements:\n",
    "                color_href = button_color_element.get_attribute('href')\n",
    "                if not color_href:\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Checking color variant: {color_href}\")\n",
    "                \n",
    "                # Mở màu sản phẩm trong tab mới\n",
    "                driver.execute_script(f\"window.open('{color_href}');\")\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "                time.sleep(5)\n",
    "                \n",
    "                try:\n",
    "                    color_element = driver.find_element(By.CSS_SELECTOR, 'div.product-detail__color p')\n",
    "                    color_value = color_element.text\n",
    "                    color_values.append(color_value)\n",
    "                    \n",
    "                    # Lấy ảnh của màu này\n",
    "                    image_elements = driver.find_elements(By.CSS_SELECTOR, 'div.product-detail__gallery img.lazyloaded, div.product-detail__gallery img')\n",
    "                    for image_element in image_elements:\n",
    "                        image_url = image_element.get_attribute('src') or image_element.get_attribute('data-src')\n",
    "                        if image_url and not \"data:image\" in image_url and image_url not in image_urls:\n",
    "                            image_urls.append(image_url)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error getting color info: {e}\")\n",
    "                \n",
    "                # Đóng tab màu sản phẩm\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "                time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting colors and images: {e}\")\n",
    "        \n",
    "        colors_string = \"_\".join(color_values) if color_values else None\n",
    "        \n",
    "        # Tạo thư mục lưu trữ\n",
    "        item_folder, image_folder = create_detail_directory(\n",
    "            paths['detail_view_dir'], \n",
    "            sku_value, \n",
    "            name_value\n",
    "        )\n",
    "        \n",
    "        # Lưu HTML source\n",
    "        save_html_source(item_folder, driver)\n",
    "        \n",
    "        # Tạo object dữ liệu sản phẩm\n",
    "        product_data = {\n",
    "            \"sku\": sku_value,\n",
    "            \"name\": name_value,\n",
    "            \"original_price\": original_price_value,\n",
    "            \"sale_price\": sale_price_value,\n",
    "            \"sizes\": sizes_string,\n",
    "            \"colors\": colors_string,\n",
    "            \"description\": description_value,\n",
    "            \"url\": product_url,\n",
    "            \"images\": image_urls\n",
    "        }\n",
    "        \n",
    "        # Lưu dữ liệu vào file JSON\n",
    "        json_path = os.path.join(item_folder, \"data.json\")\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(product_data, json_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        # Tải và lưu các hình ảnh\n",
    "        for idx, image_url in enumerate(image_urls, start=1):\n",
    "            image_name = f\"{sku_value}_{idx:02}.jpg\"\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(image_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(image_path, \"wb\") as file:\n",
    "                        file.write(response.content)\n",
    "                    print(f\"Saved Image: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving image {image_url}: {e}\")\n",
    "        \n",
    "        # Cập nhật list_done.csv\n",
    "        append_csv(paths['list_done_path'], [product_url])\n",
    "        \n",
    "        # Cập nhật detail_attempt.csv\n",
    "        detail_attempt_exists = os.path.isfile(paths['detail_attempt_path']) and os.path.getsize(paths['detail_attempt_path']) > 0\n",
    "        \n",
    "        with open(paths['detail_attempt_path'], \"a\", encoding=\"utf-8\", newline='') as f:\n",
    "            # Sử dụng DictWriter để đảm bảo định dạng CSV đúng\n",
    "            fieldnames = [\"sku\", \"name\", \"original_price\", \"sale_price\", \"sizes\", \"colors\", \"description\", \"url\", \"images\"]\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            \n",
    "            # Nếu file chưa tồn tại hoặc rỗng, ghi header\n",
    "            if not detail_attempt_exists:\n",
    "                writer.writeheader()\n",
    "            \n",
    "            # Chuyển đổi list image_urls thành string để lưu trong CSV\n",
    "            data_to_write = product_data.copy()\n",
    "            data_to_write[\"images\"] = json.dumps(product_data[\"images\"], ensure_ascii=False)\n",
    "            \n",
    "            # Ghi dữ liệu\n",
    "            writer.writerow(data_to_write)\n",
    "        \n",
    "        print(f\"Successfully scraped product: {name_value} ({sku_value})\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {product_url}: {e}\")\n",
    "        return False\n",
    "\n",
    "##### CHẶN THÔNG BÁO #####\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "prefs = {\n",
    "    \"credentials_enable_service\": False, \n",
    "    \"profile.password_manager_enabled\": False, \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "##### MAIN FUNCTION #####\n",
    "\n",
    "def crawl_links():\n",
    "    \"\"\"\n",
    "    Hàm thực hiện việc cào tất cả các links sản phẩm từ IvyModa\n",
    "    \"\"\"\n",
    "    paths = initialize_directory_structure(base_save_dir, web_url)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver.get(web_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Xóa thông báo popup nếu có\n",
    "    try:  \n",
    "        close_button = driver.find_element(By.CSS_SELECTOR, \"div.popup-content div.action-close\")\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(close_button).click().perform()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        print(\"Không có thông báo nào.\")\n",
    "    \n",
    "    # Khởi tạo ActionChains\n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    # Tìm tất cả các danh mục từ menu\n",
    "    menu_element = driver.find_element(By.CSS_SELECTOR, \"ul.menu\")\n",
    "    categorys = menu_element.find_elements(By.TAG_NAME, \"a\")\n",
    "    \n",
    "\n",
    "    for index, category in enumerate(categorys):\n",
    "        if index == 30:\n",
    "        \n",
    "            category_href = category.get_attribute('href')\n",
    "            if category_href and ('danh-muc' in category_href or 'lookbook' in category_href):\n",
    "                # Lấy tên danh mục từ URL\n",
    "                pattern = r\"(?:danh-muc|lookbook)/([^/?#]+)\"\n",
    "                match = re.search(pattern, category_href)\n",
    "                \n",
    "                if match:\n",
    "                    category_name = match.group(1).replace(\"-\", \"_\")\n",
    "                else:\n",
    "                    category_text = category.text.strip()\n",
    "                    category_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", category_text.replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "                \n",
    "                print(f\"Opening: {category_href} (Category: {category_name})\")\n",
    "                \n",
    "                # Mở tab mới cho danh mục\n",
    "                driver.execute_script(f\"window.open('{category_href}');\")\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "                time.sleep(5)\n",
    "                \n",
    "                page = 1\n",
    "                has_next_page = True\n",
    "                \n",
    "                while has_next_page:\n",
    "                    # Lấy thông tin phân trang hiện tại nếu có\n",
    "                    try:\n",
    "                        pagination = driver.find_element(By.XPATH, '//*[@id=\"products_active_ts\"]')\n",
    "                        pagination_text = pagination.text\n",
    "                    except:\n",
    "                        pagination_text = str(page)\n",
    "                    \n",
    "                    print(f\"Processing: {category_name} - Page {pagination_text}\")\n",
    "                    \n",
    "                    # Cuộn xuống để tải hết trang\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "                    # Tạo thư mục category_{pagination}\n",
    "                    category_dir, _ = create_category_directory(paths['list_view_dir'], category_name, pagination_text)\n",
    "                    \n",
    "                    # Lưu HTML của trang danh sách\n",
    "                    save_html_source(category_dir, driver)\n",
    "                    \n",
    "                    # Tìm tất cả sản phẩm trên trang theo CSS selector của IvyModa\n",
    "                    products = driver.find_elements(By.CSS_SELECTOR, \"div.item-cat-product div.product div.thumb-product a\")\n",
    "                    \n",
    "                    if not products:\n",
    "                        # Thử selector khác nếu không tìm thấy sản phẩm\n",
    "                        products = driver.find_elements(By.CSS_SELECTOR, \"div.product a.product-link\")\n",
    "                        \n",
    "                    if not products:\n",
    "                        # Thử selector khác nếu vẫn không tìm thấy sản phẩm\n",
    "                        products = driver.find_elements(By.CSS_SELECTOR, \"div.product a\")\n",
    "                    \n",
    "                    if products:\n",
    "                        # Lưu thông tin sản phẩm và lấy các links\n",
    "                        product_links = save_product_data(category_dir, products, actions)\n",
    "                        \n",
    "                        # Cập nhật các file CSV\n",
    "                        update_product_links(paths, product_links)\n",
    "                    else:\n",
    "                        print(f\"Không tìm thấy sản phẩm nào trong trang {pagination_text}\")\n",
    "                    \n",
    "                    # Kiểm tra nút phân trang next\n",
    "                    try:\n",
    "                        next_page = driver.find_element(By.XPATH, '//li[@class=\"last-page\"]/preceding-sibling::li[1]')\n",
    "                        actions.move_to_element(next_page).click().perform()\n",
    "                        page += 1\n",
    "                        time.sleep(5)  # Đợi trang mới tải xong\n",
    "                    except Exception as e:\n",
    "                        print(f\"Không tìm thấy nút next page hoặc đã hết trang: {e}\")\n",
    "                        has_next_page = False\n",
    "                \n",
    "                # Đóng tab sau khi xử lý xong danh mục\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "    driver.quit()\n",
    "    return paths\n",
    "\n",
    "def crawl_details(paths):\n",
    "    \"\"\"\n",
    "    Hàm thực hiện việc cào chi tiết tất cả các sản phẩm từ list_add.csv\n",
    "    \"\"\"\n",
    "    # Đọc danh sách links cần cào chi tiết từ list_add.csv\n",
    "    list_add_path = paths['list_add_path']\n",
    "    list_done_path = paths['list_done_path']\n",
    "    \n",
    "    links_to_scrape = load_csv(list_add_path)\n",
    "    links_done = load_csv(list_done_path)\n",
    "    \n",
    "    # Lọc ra các links chưa được cào\n",
    "    links_to_scrape = links_to_scrape - links_done\n",
    "    \n",
    "    if not links_to_scrape:\n",
    "        print(\"Không có links mới cần cào chi tiết\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Bắt đầu cào chi tiết cho {len(links_to_scrape)} sản phẩm mới\")\n",
    "    \n",
    "    # Khởi tạo driver mới\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Cào chi tiết từng sản phẩm\n",
    "    for i, link in enumerate(links_to_scrape):\n",
    "        print(f\"Cào chi tiết sản phẩm {i+1}/{len(links_to_scrape)}: {link}\")\n",
    "        success = scrape_product_detail(driver, link, paths)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"Hoàn thành cào chi tiết: {link}\")\n",
    "        else:\n",
    "            print(f\"Thất bại khi cào chi tiết: {link}\")\n",
    "        \n",
    "        # Delay giữa các lần request để tránh bị block\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Hoàn thành và đóng trình duyệt\n",
    "    print(f\"Hoàn thành cào chi tiết cho {len(links_to_scrape)} sản phẩm\")\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính thực hiện quá trình cào: \n",
    "    1. Cào tất cả links sản phẩm từ categories \n",
    "    2. Sau đó cào chi tiết các sản phẩm\n",
    "    \"\"\"\n",
    "    print(\"Bắt đầu quá trình cào dữ liệu...\")\n",
    "    \n",
    "    print(\"=== PHASE 1: Crawling category links ===\")\n",
    "    paths = crawl_links()\n",
    "    \n",
    "    print(\"=== PHASE 2: Crawling product details ===\")\n",
    "    crawl_details(paths)\n",
    "    \n",
    "    print(\"Hoàn thành toàn bộ quá trình cào dữ liệu!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
